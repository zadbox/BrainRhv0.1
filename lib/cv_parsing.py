# -*- coding: utf-8 -*-
"""
Module de parsing de CVs - Logique pure sans d√©pendances Streamlit
Extraction texte (PDF/DOCX) + Parsing LLM + Nettoyage JSON
"""

import os
import json
import re
from pathlib import Path
from typing import Dict, Any, Optional
import fitz  # PyMuPDF
import docx2txt
from openai import OpenAI
from dotenv import load_dotenv
import logging

from lib.models import CV, CVParseResult

# Charger variables d'environnement
load_dotenv()

logger = logging.getLogger(__name__)

# ==================== PROMPTS ====================

PROMPT_CV_EXTRACTION = """
Tu es un expert en ressources humaines avec une attention m√©ticuleuse aux d√©tails. Tu re√ßois un CV sous forme de texte brut.

**PROCESSUS EN 3 √âTAPES OBLIGATOIRES :**

1. **EXTRACTION EXHAUSTIVE** : Lis attentivement TOUT le CV et identifie TOUTES les informations pertinentes, sans rien omettre. N'oublie aucun d√©tail, m√™me mineur.

2. **V√âRIFICATION APPROFONDIE** : Relis le CV une seconde fois pour t'assurer que :
   - Toutes les comp√©tences techniques mentionn√©es sont bien extraites (frameworks, langages, outils, technologies)
   - Toutes les exp√©riences professionnelles sont compl√®tes avec leurs missions d√©taill√©es
   - Tous les dipl√¥mes et certifications sont captur√©s
   - Toutes les langues mentionn√©es sont incluses
   - Aucune information importante n'a √©t√© oubli√©e

3. **STRUCTURATION JSON** : G√©n√®re un JSON strictement valide avec les informations v√©rifi√©es.

Ta t√¢che est d'extraire uniquement les informations suivantes et de r√©pondre uniquement avec un JSON strictement valide, sans aucune explication ou texte suppl√©mentaire.

Structure √† respecter :

{
  "identite": {
    "nom": "",
    "prenom": "",
    "email": "",
    "telephone": "",
    "adresse": "",
    "linkedin": "",
    "autres_reseaux": []
  },
  "titre": "",
  "resume_professionnel": "",
  "competences_techniques": [],
  "competences_transversales": [],
  "langues":[],
  "experiences_professionnelles": [
    {
      "poste": "",
      "entreprise": "",
      "lieu": "",
      "date_debut": "",
      "date_fin": "",
      "dur√©e": "",
      "missions": []
    }
  ],
  "formations": [
    {
      "diplome": "",
      "ecole": "",
      "annee_obtention": "",
      "niveau": "",
      "specialite": ""
    }
    ],
  "certifications": [
    {
      "nom": "",
      "organisme": "",
      "annee": ""
    }
  ],
  "projets": [
    {
      "titre": "",
      "description": "",
      "technologies": []
    }
  ],
  "mobilite": {
    "permis_conduire": false,
    "disponibilite_geographique": ""
  },
  "autres": {
    "loisirs": [],
    "engagements": []
  }
}

**R√àGLES D'EXTRACTION STRICTES :**
- Respecte strictement cette structure, et n'ajoute rien.
- Pour des langues, seule la langue a mentionnee sans avoir plus de details.
- Pour les formations, seul le dernier dipl√¥me (le plus r√©cent) doit inclure les champs "niveau" (ex. : Bac+3, Bac+5) et "specialite" (ex. : Informatique, Gestion...).
- Si une information n'est pas trouv√©e, laisse la cha√Æne vide ("") ou une liste vide ([]), mais ne supprime aucun champ.
- La dur√©e d'une exp√©rience doit √™tre indiqu√©e dans le champ "dur√©e", par exemple : "2 mois", "1 an et demi", etc.
- La r√©ponse doit √™tre *strictement du JSON*, sans aucun texte avant ni apr√®s.

**RAPPEL FINAL** : Avant de r√©pondre, v√©rifie une derni√®re fois que tu as extrait TOUTES les informations du CV, sans aucune omission. L'exhaustivit√© est cruciale.
"""

# ==================== EXTRACTION TEXTE ====================

def extract_text_from_pdf(pdf_path: str) -> str:
    """
    Extrait le texte d'un fichier PDF avec PyMuPDF

    Args:
        pdf_path: Chemin vers le fichier PDF

    Returns:
        Texte extrait du PDF
    """
    import logging
    logger = logging.getLogger(__name__)
    
    pdf_path = str(pdf_path)
    logger.info(f"üìÑ Extraction PDF: {Path(pdf_path).name}")
    
    if not Path(pdf_path).exists():
        logger.error(f"‚ùå Fichier PDF introuvable: {pdf_path}")
        raise FileNotFoundError(f"Fichier PDF introuvable: {pdf_path}")
    
    file_size = Path(pdf_path).stat().st_size
    logger.info(f"  üìè Taille: {file_size} bytes")

    try:
        # Charger le PDF en m√©moire pour √©viter les probl√®mes de handle ferm√©
        with open(pdf_path, "rb") as f:
            pdf_bytes = f.read()
        logger.info(f"  ‚úÖ {len(pdf_bytes)} bytes lus en m√©moire")

        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        logger.info(f"  üìñ PDF ouvert: {doc.page_count} pages")
        
        try:
            text = "".join(page.get_text() for page in doc)
            logger.info(f"  ‚úÖ {len(text)} caract√®res extraits")
            return text
        finally:
            doc.close()
    except Exception as e:
        logger.error(f"  ‚ùå Erreur: {type(e).__name__}: {str(e)}")
        raise


def extract_text_from_docx(docx_path: str) -> str:
    """
    Extrait le texte d'un fichier DOCX

    Args:
        docx_path: Chemin vers le fichier DOCX

    Returns:
        Texte extrait du DOCX
    """
    return docx2txt.process(docx_path)


def extract_text_from_file(file_path: str) -> str:
    """
    Extrait le texte d'un fichier (PDF ou DOCX)

    Args:
        file_path: Chemin vers le fichier

    Returns:
        Texte extrait

    Raises:
        ValueError: Si le format de fichier n'est pas support√©
    """
    ext = Path(file_path).suffix.lower()

    if ext == ".pdf":
        return extract_text_from_pdf(file_path)
    elif ext == ".docx":
        return extract_text_from_docx(file_path)
    else:
        raise ValueError(f"Format de fichier non support√©: {ext}. Accept√©: .pdf, .docx")


# ==================== NETTOYAGE JSON ====================

def clean_json_text(text: str) -> str:
    """
    Nettoie le texte JSON g√©n√©r√© par le LLM
    Supprime les balises markdown et normalise les guillemets

    Args:
        text: Texte JSON brut du LLM

    Returns:
        Texte JSON nettoy√©
    """
    # Supprime les balises de code Markdown (```json ... ```)
    text = re.sub(r"```(?:json)?\s*", "", text)
    text = re.sub(r"\s*```", "", text)

    # Remplace les guillemets typographiques par des guillemets standards
    text = text.replace(""", '"').replace(""", '"')
    text = text.replace("'", "'").replace("'", "'")

    return text.strip()


# ==================== PARSING LLM ====================

def parse_cv_with_llm(
    cv_text: str,
    model: str = "gpt-5-mini",
    openai_client: Optional[OpenAI] = None
) -> Dict[str, Any]:
    """
    Parse un CV avec le LLM

    Args:
        cv_text: Texte brut du CV
        model: Mod√®le LLM √† utiliser
        openai_client: Client OpenAI (cr√©√© automatiquement si None)

    Returns:
        Dict contenant les donn√©es structur√©es du CV

    Raises:
        ValueError: Si la r√©ponse LLM n'est pas un JSON valide
    """
    # Cr√©er client si non fourni
    if openai_client is None:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY non trouv√©e dans les variables d'environnement")
        # PAS DE TIMEOUT - laissons l'API prendre son temps
        openai_client = OpenAI(api_key=api_key)

    # Appel LLM avec logs d√©taill√©s
    import time
    api_call_start = time.time()
    logger.info(f"[DEBUG] Appel API OpenAI d√©marr√© √† {time.strftime('%H:%M:%S')}")
    logger.info(f"[DEBUG] Mod√®le: {model}")
    logger.info(f"[DEBUG] Input tokens estim√©s: {(len(PROMPT_CV_EXTRACTION) + len(cv_text)) // 4}")

    response = openai_client.chat.completions.create(
        model=model,
        messages=[
            {
                "role": "system",
                "content": "Tu es un assistant qui analyse des CV. Tu r√©ponds UNIQUEMENT en JSON valide."
            },
            {
                "role": "user",
                "content": f"{PROMPT_CV_EXTRACTION}\n\n{cv_text}"
            }
        ],
        response_format={"type": "json_object"}
        # Pas de temperature pour GPT-5-mini (valeur par d√©faut 1.0)
    )

    api_call_end = time.time()
    api_duration = api_call_end - api_call_start

    # Extraire les m√©tadonn√©es de la r√©ponse
    usage = response.usage if hasattr(response, 'usage') else None

    logger.info(f"[DEBUG] R√©ponse re√ßue apr√®s {api_duration:.3f}s")
    if usage:
        logger.info(f"[DEBUG] Usage tokens: input={usage.prompt_tokens}, output={usage.completion_tokens}, total={usage.total_tokens}")

    # Extraire et nettoyer la r√©ponse
    result_text = response.choices[0].message.content
    logger.info(f"[DEBUG] Longueur r√©ponse: {len(result_text)} caract√®res")
    cleaned_result = clean_json_text(result_text)

    # Parser JSON
    try:
        parsed_data = json.loads(cleaned_result)
        return parsed_data
    except json.JSONDecodeError as e:
        raise ValueError(f"R√©ponse LLM n'est pas un JSON valide: {str(e)}\nR√©ponse brute: {cleaned_result[:500]}")


# ==================== FONCTION PRINCIPALE ====================

def parse_cv_from_file(
    file_path: str,
    model: str = "gpt-5-mini",
    openai_client: Optional[OpenAI] = None
) -> CVParseResult:
    """
    Parse un CV complet (extraction texte + LLM + validation)

    Args:
        file_path: Chemin vers le fichier CV (PDF ou DOCX)
        model: Mod√®le LLM √† utiliser
        openai_client: Client OpenAI (cr√©√© automatiquement si None)

    Returns:
        CVParseResult avec succ√®s/√©chec et donn√©es
    """
    import time

    filename = Path(file_path).name
    start_time = time.time()

    try:
        # √âtape 1: Extraction texte
        extraction_start = time.time()
        cv_text = extract_text_from_file(file_path)
        extraction_duration = time.time() - extraction_start

        # √âtape 2: Parsing LLM
        parsing_start = time.time()
        parsed_data = parse_cv_with_llm(cv_text, model, openai_client)
        parsing_duration = time.time() - parsing_start

        # √âtape 3: Validation avec Pydantic
        cv_data = CV(cv=filename, **parsed_data)

        total_duration = time.time() - start_time

        return CVParseResult(
            filename=filename,
            success=True,
            data=cv_data,
            error=None,
            timings={
                "extraction": round(extraction_duration, 3),
                "parsing": round(parsing_duration, 3),
                "total": round(total_duration, 3)
            }
        )

    except Exception as e:
        total_duration = time.time() - start_time

        return CVParseResult(
            filename=filename,
            success=False,
            data=None,
            error=str(e),
            timings={
                "total": round(total_duration, 3),
                "error": True
            }
        )


# ==================== UTILITAIRES ====================

def get_openai_client() -> OpenAI:
    """
    Cr√©e et retourne un client OpenAI configur√©

    Returns:
        Client OpenAI

    Raises:
        ValueError: Si OPENAI_API_KEY n'est pas d√©finie
    """
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEY non trouv√©e dans les variables d'environnement")

    # PAS DE TIMEOUT - le timeout est g√©r√© par asyncio.wait_for() dans parallel_engine
    return OpenAI(api_key=api_key)
