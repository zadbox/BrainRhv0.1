"""
Module de matching CV/Offre refactorisÃ© avec scoring amÃ©liorÃ©
Inclut: embeddings, filtrage must-have, scoring nice-have, bonus expÃ©riences, re-ranking LLM
V2: Validation avec jsonschema + parallÃ©lisation
"""

import os
import json
import re
import hashlib
import numpy as np
import time
import requests
from typing import Dict, List, Any, Tuple
from pathlib import Path

from sentence_transformers import SentenceTransformer
from openai import OpenAI
from dotenv import load_dotenv
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

# Import modules V2
from validation import validate_and_repair, check_cv_size, check_min_content
from parallel_processing import ParallelPipeline
from lib.experience_analyzer import detect_gaps_and_overlaps, format_flags_for_llm
from lib.models import Evidence, EvidenceMap, Flags

load_dotenv()


class MatchingEngine:
    """Moteur de matching CV/Offre avec scoring intelligent"""

    def __init__(self, config: Dict[str, Any] = None):
        """
        Initialise le moteur de matching

        Args:
            config: Configuration (dict depuis config.yaml via config_loader)
        """
        self.config = config or self._default_config()

        # Initialiser le modÃ¨le d'embeddings
        self.embedding_model = SentenceTransformer(
            self.config.get("embeddings", {}).get("model", "all-MiniLM-L6-v2")
        )

        # Initialiser le client OpenAI
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("âŒ OPENAI_API_KEY non trouvÃ©e")

        self.openai_client = OpenAI(api_key=api_key)
        self.llm_model = self.config.get("llm", {}).get("model", "gpt-5-mini")
        self.fallback_models = self.config.get("llm", {}).get("fallback_models", ["gpt-4.1-mini", "gpt-5-mini"])

        # TempÃ©ratures pour les diffÃ©rents usages
        # NOTE: Ces tempÃ©ratures sont utilisÃ©es UNIQUEMENT pour xAI (Grok) et l'extraction
        # GPT-5 mini ne supporte PAS le paramÃ¨tre temperature (erreur 400 si fourni)
        self.temperature_extraction = self.config.get("llm", {}).get("temperature_extraction", 0.1)
        self.temperature_reranking = self.config.get("llm", {}).get("temperature_reranking", 0.2)  # Pour xAI uniquement
        
        # Seed pour dÃ©terminisme (mÃªme seed = mÃªmes rÃ©sultats)
        self.seed = self.config.get("llm", {}).get("seed", 42)

        # Technical info removed from UI as requested
        # print(f"âœ… Engine initialisÃ© avec modÃ¨le: {self.llm_model} (temp_extract={self.temperature_extraction}, temp_rerank={self.temperature_reranking})")

        # Configuration de scoring
        self.scoring_config = self.config.get("scoring", {})

        # Cache pour embeddings
        self.cache_folder = Path(self.config.get("paths", {}).get("cache_folder", "cache"))
        self.cache_folder.mkdir(parents=True, exist_ok=True)

        # V2: Pipeline de parallÃ©lisation
        self.pipeline = ParallelPipeline(
            max_file_workers=self.config.get("parallel", {}).get("file_workers", 4),
            max_llm_concurrent=self.config.get("parallel", {}).get("llm_concurrent", 5),
            openai_client=self.openai_client
        )

        # V2: Flags de validation
        self.validate_outputs = self.config.get("validation", {}).get("enabled", True)
        self.max_repair_attempts = self.config.get("validation", {}).get("max_repair_attempts", 3)

    def _default_config(self) -> Dict:
        """Configuration par dÃ©faut"""
        return {
            "llm": {"model": "gpt-5-mini"},
            "scoring": {
                "top_k": 50,
                "top_rerank": 10,
                "nice_have_malus_factor": 0.95,
                "bonus_experience_exacte": 0.15,
                "bonus_experience_tres_proche": 0.10,
                "bonus_experience_proche": 0.05,
                "score_min": 0.0,
                "score_max": 1.0,
                "reranking_provider": "openai"  # Default: OpenAI (peut Ãªtre "xai" pour Grok)
            },
            "embeddings": {"model": "all-MiniLM-L6-v2", "cache_enabled": True},
            "paths": {"cache_folder": "cache"}
        }

    def clean_text(self, text: str) -> str:
        """Nettoie et normalise le texte"""
        if not text:
            return ""
        return re.sub(r"\s+", " ", text.lower().replace("\xa0", " ").strip())

    def _flatten_cv_text(self, cv: Dict) -> List[str]:
        """Aplatit le CV en liste de textes"""
        cv_text = []

        # GÃ©rer les deux formats: avec ou sans wrapper "sections"
        if "sections" in cv:
            cv_data = cv["sections"]
        elif "content" in cv:
            cv_data = cv["content"]
        else:
            cv_data = cv

        for k, v in cv_data.items():
            if k in ["cv", "identite"]:  # Ignorer le nom du fichier et l'identitÃ©
                continue

            # SKIP null values
            if v is None:
                continue

            if isinstance(v, list):
                cv_text.extend([self.clean_text(str(x)) for x in v if x is not None])
            elif isinstance(v, dict):
                # Pour les dicts (comme mobilite), aplatir rÃ©cursivement
                for sub_v in v.values():
                    if sub_v is not None:
                        cv_text.append(self.clean_text(str(sub_v)))
            else:
                cv_text.append(self.clean_text(str(v)))

        return cv_text

    def _find_nice_have_missing(self, cv: Dict, nice_have_list: List[str], job_description: str) -> List[str]:
        """Recherche sÃ©mantique des nice-have manquants"""
        if not nice_have_list:
            return []

        cv_text = json.dumps(cv, ensure_ascii=False)

        prompt = f"""
        Tu es un expert RH qui analyse sÃ©mantiquement les CVs.

        OFFRE D'EMPLOI :
        {job_description}

        NICE-HAVE Ã€ CHERCHER (critÃ¨res bonus) :
        {json.dumps(nice_have_list, ensure_ascii=False)}

        CV Ã€ ANALYSER :
        {cv_text}

        TÃ‚CHE :
        Identifie quels nice-have sont prÃ©sents dans ce CV (mÃªme de maniÃ¨re sÃ©mantique).

        RÃ©ponds UNIQUEMENT en JSON :
        {{
            "nice_have_presents": ["nice-have 1", "nice-have 2"],
            "nice_have_manquants": ["nice-have 3", "nice-have 4"]
        }}

        RÃˆGLES :
        - Si un nice-have est mentionnÃ© explicitement ou sÃ©mantiquement â†’ l'ajouter Ã  "presents"
        - Si un nice-have n'est pas trouvÃ© â†’ l'ajouter Ã  "manquants"
        - ÃŠtre gÃ©nÃ©reux dans l'interprÃ©tation sÃ©mantique pour les nice-have
        """

        response = self.openai_client.chat.completions.create(
            model=self.llm_model,
            messages=[
                {"role": "system", "content": "Tu es un assistant RH expert en analyse sÃ©mantique. Tu rÃ©ponds UNIQUEMENT en JSON valide."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"},
            seed=self.seed  # DÃ©terminisme: mÃªme seed = mÃªmes rÃ©sultats
            # GPT-5 mini: pas de paramÃ¨tre temperature
        )

        result = self._safe_json_parse(response.choices[0].message.content)

        if isinstance(result, dict):
            return result.get("nice_have_manquants", [])

        return nice_have_list

    def _analyze_experience_bonus(self, cv: Dict, job_description: str) -> float:
        """
        Analyse les expÃ©riences et retourne un MULTIPLICATEUR (1.0 Ã  1.15)

        Returns:
            float: Multiplicateur entre 1.0 (aucune exp pertinente) et 1.15 (expÃ©rience trÃ¨s pertinente)
        """
        cv_text = json.dumps(cv, ensure_ascii=False)

        prompt = f"""
        Tu es un expert RH qui analyse les expÃ©riences professionnelles des candidats.

        OFFRE D'EMPLOI :
        {job_description}

        CV Ã€ ANALYSER :
        {cv_text}

        TÃ‚CHE :
        Analyse la section "expÃ©riences_professionnelles" du CV et Ã©value la pertinence :
        - ExpÃ©rience TRÃˆS PERTINENTE au poste (mÃªme domaine, mÃªme niveau) â†’ multiplicateur 1.15
        - ExpÃ©rience PERTINENTE (domaine proche, niveau similaire) â†’ multiplicateur 1.10
        - ExpÃ©rience PARTIELLEMENT PERTINENTE (quelques similitudes) â†’ multiplicateur 1.05
        - Aucune expÃ©rience pertinente â†’ multiplicateur 1.0

        RÃˆGLES:
        - Prends la MEILLEURE expÃ©rience (pas cumul)
        - ConsidÃ¨re le domaine, le niveau de responsabilitÃ©, les technologies
        - Sois strict: seules les vraies expÃ©riences pertinentes comptent

        RÃ©ponds UNIQUEMENT en JSON :
        {{
            "pertinence": "TRÃˆS PERTINENTE" | "PERTINENTE" | "PARTIELLEMENT PERTINENTE" | "NON PERTINENTE",
            "justification": "phrase courte expliquant pourquoi",
            "multiplicateur": 1.15 | 1.10 | 1.05 | 1.0
        }}
        """

        try:
            response = self.openai_client.chat.completions.create(
                model=self.llm_model,
                messages=[
                    {"role": "system", "content": "Tu es un assistant RH expert. Tu rÃ©ponds UNIQUEMENT en JSON valide."},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
                seed=self.seed  # DÃ©terminisme: mÃªme seed = mÃªmes rÃ©sultats
                # GPT-5 mini: pas de paramÃ¨tre temperature
            )

            result = self._safe_json_parse(response.choices[0].message.content)

            if isinstance(result, dict):
                mult = result.get("multiplicateur", 1.0)
                # SÃ©curitÃ©: clamp entre 1.0 et 1.15
                return max(1.0, min(1.15, float(mult)))

        except Exception as e:
            print(f"âš ï¸ Erreur bonus expÃ©riences: {str(e)}")

        return 1.0

    def vectorize_text(self, text_list: List[str]) -> np.ndarray:
        """Vectorise une liste de textes (ancienne mÃ©thode, garde pour compatibilitÃ©)"""
        if not text_list:
            return np.zeros((1, self.embedding_model.get_sentence_embedding_dimension()))

        joined = " ".join(text_list)

        # Cache des embeddings
        if self.config.get("cache", {}).get("enabled", True):
            cache_key = hashlib.sha256(joined.encode()).hexdigest()
            cache_file = self.cache_folder / f"emb_{cache_key}.npy"

            if cache_file.exists():
                return np.load(cache_file)

            # Calculer et cacher
            embedding = self.embedding_model.encode([joined])
            np.save(cache_file, embedding)
            return embedding

        return self.embedding_model.encode([joined])

    def vectorize_many_docs(self, docs_as_lists: List[List[str]], batch_size: int = None, normalize: bool = True) -> np.ndarray:
        """
        Vectorise plusieurs documents en batch (optimisÃ©)

        Args:
            docs_as_lists: Liste de listes de strings (sections de CV aplaties)
            batch_size: Taille du batch (dÃ©faut: depuis config)
            normalize: Normaliser les embeddings (True pour cosine via dot product)

        Returns:
            np.ndarray de shape (N, d) en float32 normalisÃ©
        """
        if not docs_as_lists:
            dim = self.embedding_model.get_sentence_embedding_dimension()
            return np.zeros((0, dim), dtype=np.float32)

        # ConcatÃ©ner chaque liste en une chaÃ®ne
        texts = [" ".join(parts) for parts in docs_as_lists]

        # Batch size depuis config
        if batch_size is None:
            batch_size = self.config.get("embeddings", {}).get("batch_size", 32)

        # Encoder en batch
        embeddings = self.embedding_model.encode(
            texts,
            batch_size=batch_size,
            convert_to_numpy=True,
            normalize_embeddings=normalize,
            show_progress_bar=False
        )

        # Assurer float32
        return embeddings.astype(np.float32)

    def extract_must_have_with_llm(self, job_description: str) -> List[str]:
        """
        Extrait les must-have depuis l'offre avec LLM (format concis)

        Args:
            job_description: Description de l'offre

        Returns:
            Liste de must-have extraits (concis, actionnables, dÃ©dupliquÃ©s)
        """
        prompt = f"""Tu es un expert RH spÃ©cialisÃ© dans l'analyse d'offres d'emploi. Ta mission: identifier les critÃ¨res CRITIQUES qui sont essentiels pour le poste.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DÃ‰FINITION: Qu'est-ce qu'un CRITÃˆRE CRITIQUE ?
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Un critÃ¨re est CRITIQUE si:
âœ“ L'offre utilise un vocabulaire IMPÃ‰RATIF: "requis", "obligatoire", "indispensable", "minimum", "impÃ©ratif", "nÃ©cessaire"
âœ“ OU l'absence du critÃ¨re rend le candidat PEU QUALIFIÃ‰ pour le poste
âœ“ OU une durÃ©e/niveau MINIMUM est explicitement mentionnÃ© (ex: "minimum 5 ans", "au moins Bac+5")

âš ï¸ IMPORTANT: Extraire AU MINIMUM 10 critÃ¨res (idÃ©alement 10-15)

Un critÃ¨re N'EST PAS un must-have si:
âœ— Vocabulaire OPTIONNEL: "souhaitÃ©", "apprÃ©ciÃ©", "serait un plus", "idÃ©alement", "de prÃ©fÃ©rence", "atout", "bonus"
âœ— Formulation VAGUE sans seuil: "expÃ©rience confirmÃ©e", "bonne connaissance" (sans durÃ©e prÃ©cise)
âœ— CONTEXTE d'entreprise: lieu, type de contrat, secteur d'activitÃ©, environnement de travail

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RÃˆGLES D'EXTRACTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. PRÃ‰CISION MAXIMALE
   - Toujours inclure les durÃ©es/niveaux chiffrÃ©s: "10+ ans", "Bac+5", "Niveau C1"
   - Conserver les contextes importants: "Management Ã©quipe 20+ personnes", "Budget 5Mâ‚¬+"

2. CONCISION (max 10 mots)
   - âœ… BON: "Minimum 10 ans expÃ©rience architecture SI"
   - âœ… BON: "Python et Django 5+ ans"
   - âŒ MAUVAIS: "ExpÃ©rience au sein d'une DSI de plusieurs centaines de collaborateurs dans un contexte de transformation digitale"

3. IGNORER SYSTÃ‰MATIQUEMENT
   - Localisation gÃ©ographique (Paris, Ãle-de-France, etc.)
   - Type de contrat (CDI, CDD, freelance, temps plein/partiel)
   - Secteur d'activitÃ© (banque, industrie, etc.)
   - Soft skills gÃ©nÃ©riques (rigueur, autonomie, esprit d'Ã©quipe)

4. DÃ‰TECTER LES FAUX MUST-HAVES
   - "Une certification X serait un plus" â†’ IGNORER (optionnel)
   - "IdÃ©alement niveau Y" â†’ IGNORER (souhaitÃ© mais pas exigÃ©)
   - "ExpÃ©rience en Z apprÃ©ciÃ©e" â†’ IGNORER (nice-to-have)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EXEMPLES RÃ‰ELS PAR CATÃ‰GORIE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ DIPLÃ”ME:
âœ… "Bac+5 informatique ou Ã©quivalent"
âœ… "DiplÃ´me ingÃ©nieur requis"
âœ… "Master en data science"

ğŸ’¼ EXPÃ‰RIENCE (toujours avec durÃ©e si mentionnÃ©e):
âœ… "Minimum 10 ans architecture SI"
âœ… "5+ ans gestion projet IT"
âœ… "ExpÃ©rience management 20+ personnes"
âœ… "7 ans minimum dÃ©veloppement backend"

ğŸ’» COMPÃ‰TENCES TECHNIQUES:
âœ… "Python et Django"
âœ… "AWS certifiÃ©"
âœ… "MaÃ®trise SQL et PostgreSQL"
âœ… "Docker et Kubernetes"

ğŸ—£ï¸ LANGUES:
âœ… "Anglais courant exigÃ©"
âœ… "Anglais niveau C1 minimum"
âœ… "Bilingue franÃ§ais-anglais"

ğŸ† CERTIFICATIONS:
âœ… "PMP obligatoire"
âœ… "Certification AWS Solutions Architect"
âœ… "TOGAF certifiÃ© requis"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CAS LIMITES - COMMENT TRANCHER ?
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â“ "ExpÃ©rience significative en Java"
â†’ IGNORER (pas de seuil chiffrÃ© = trop vague)

â“ "Au moins 3 ans en dÃ©veloppement Python requis"
â†’ âœ… EXTRAIRE: "Minimum 3 ans dÃ©veloppement Python"

â“ "Connaissance de Docker et Kubernetes serait un atout"
â†’ IGNORER ("atout" = nice-to-have)

â“ "ImpÃ©ratif d'avoir gÃ©rÃ© des Ã©quipes de 10+ personnes"
â†’ âœ… EXTRAIRE: "Management Ã©quipe 10+ personnes"

â“ "BasÃ© Ã  Paris ou Ãle-de-France"
â†’ IGNORER (localisation)

â“ "CDI temps plein"
â†’ IGNORER (type de contrat)

â“ "Minimum 15 ans d'expÃ©rience dans le secteur bancaire avec gestion de projets rÃ©glementaires"
â†’ âœ… EXTRAIRE: "Minimum 15 ans expÃ©rience secteur bancaire" (limite: 10 mots)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
OFFRE Ã€ ANALYSER
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{job_description}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FORMAT DE SORTIE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Retourne UNIQUEMENT un JSON conforme Ã  ce schÃ©ma:
{{
  "must_haves": [
    "critÃ¨re 1",
    "critÃ¨re 2",
    ...
  ]
}}

âš ï¸ Si AUCUN critÃ¨re Ã©liminatoire n'est trouvÃ© â†’ {{"must_haves": []}}
âš ï¸ Maximum 10 mots par critÃ¨re
âš ï¸ Toujours inclure les durÃ©es/niveaux chiffrÃ©s quand mentionnÃ©s"""

        try:
            response = self.openai_client.chat.completions.create(
                model=self.llm_model,
                messages=[
                    {"role": "system", "content": "Tu es un expert RH spÃ©cialisÃ© dans l'identification de critÃ¨res Ã©liminatoires. Tu rÃ©ponds UNIQUEMENT en JSON valide avec des critÃ¨res concis (max 10 mots chacun)."},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
                seed=self.seed  # DÃ©terminisme: mÃªme seed = mÃªmes rÃ©sultats
                # GPT-5 mini: pas de paramÃ¨tre temperature
            )

            content = response.choices[0].message.content
            print(f"[DEBUG] RÃ©ponse LLM must-have (premiers 200 chars): {content[:200]}")

            result = self._safe_json_parse(content)

            # Validation du format
            if not isinstance(result, dict):
                print(f"âš ï¸ Format must_have invalide: {type(result)} - Contenu: {result}")
                return []

            if "must_haves" not in result:
                print(f"âš ï¸ ClÃ© 'must_haves' manquante. ClÃ©s trouvÃ©es: {list(result.keys())}")
                return []

            must_haves_raw = result.get("must_haves", [])

            if not must_haves_raw:
                print("âš ï¸ Aucun must-have extrait de l'offre (liste vide)")
                return []

            if len(must_haves_raw) < 10:
                print(f"âš ï¸ Seulement {len(must_haves_raw)} critÃ¨res extraits (minimum recommandÃ©: 10)")

            print(f"âœ… {len(must_haves_raw)} must-have(s) brut(s) extraits")

        except Exception as e:
            print(f"âŒ Erreur lors de l'extraction des must-haves: {str(e)}")
            import traceback
            traceback.print_exc()
            return []

        # Nettoyer et dÃ©dupliquer
        must_haves_clean = []
        seen = set()

        for mh in must_haves_raw:
            # Assurer que c'est une string
            if not isinstance(mh, str):
                print(f"âš ï¸ CritÃ¨re ignorÃ© (pas une string): {type(mh)}")
                continue

            # Nettoyer (trim, lowercase pour dÃ©duplication)
            mh_clean = mh.strip()
            mh_lower = mh_clean.lower()

            # Ignorer les critÃ¨res vides
            if not mh_clean:
                print(f"âš ï¸ CritÃ¨re vide ignorÃ©")
                continue

            # Ignorer les critÃ¨res trop longs (>100 chars = phrase entiÃ¨re)
            # Note: 10 mots â‰ˆ 70 chars, on laisse une marge
            if len(mh_clean) > 100:
                print(f"âš ï¸ CritÃ¨re trop long ignorÃ© (>{len(mh_clean)} chars): {mh_clean[:60]}...")
                continue

            # Ignorer localisation/contrat (UNIQUEMENT si c'est le contenu PRINCIPAL du critÃ¨re)
            skip_keywords = ['cdi', 'temps plein', 'paris', 'tÃ©lÃ©travail', 'remote', 'prÃ©sentiel']
            # Ne filtrer que si le mot-clÃ© reprÃ©sente plus de 30% du critÃ¨re
            is_location_contract = False
            for kw in skip_keywords:
                if kw in mh_lower and len(kw) / len(mh_lower) > 0.3:
                    print(f"âš ï¸ CritÃ¨re localisation/contrat ignorÃ©: '{mh_clean}'")
                    is_location_contract = True
                    break

            if is_location_contract:
                continue

            # DÃ©dupliquer
            if mh_lower not in seen:
                seen.add(mh_lower)
                must_haves_clean.append(mh_clean)
                print(f"âœ… Must-have acceptÃ©: '{mh_clean}'")
            else:
                print(f"âš ï¸ CritÃ¨re dupliquÃ© ignorÃ©: '{mh_clean}'")

        print(f"ğŸ“Š Must-haves extraits: {len(must_haves_raw)} bruts â†’ {len(must_haves_clean)} aprÃ¨s nettoyage")

        return must_haves_clean

    def check_single_cv_must_have(
        self,
        cv: Dict,
        indispensables: List[str],
        job_description: str,
        timeout_s: int = 20
    ) -> Tuple[bool, str, Dict]:
        """
        VÃ©rifie si un CV unique satisfait tous les must-have (format amÃ©liorÃ©)

        Args:
            cv: CV Ã  vÃ©rifier
            indispensables: Liste des critÃ¨res indispensables
            job_description: Description de l'offre (contexte)
            timeout_s: Timeout en secondes pour l'appel LLM

        Returns:
            Tuple (accepted: bool, rationale: str, raw_trace: dict)
        """
        cv_name = cv.get('cv', 'CV sans nom')

        # Liste numÃ©rotÃ©e des critÃ¨res
        criteres_liste = "\n".join([f"{j+1}. {critere}" for j, critere in enumerate(indispensables)])

        prompt = f"""Tu es un expert RH spÃ©cialisÃ© en filtrage must-have STRICT.

ğŸ¯ MISSION: VÃ©rifier si ce CV satisfait TOUS les critÃ¨res indispensables de l'offre.

ğŸ“‹ CRITÃˆRES INDISPENSABLES (TOUS obligatoires):
{criteres_liste}

ğŸ“„ CV Ã€ ANALYSER:
{json.dumps(cv, ensure_ascii=False, indent=2)}

ğŸ” CONTEXTE OFFRE:
{job_description}

âš ï¸ RÃˆGLES DE VÃ‰RIFICATION:

1. **EXIGENCE STRICTE**: UN SEUL critÃ¨re manquant = Ã‰LIMINATION immÃ©diate (sauf flexibilitÃ© expÃ©rience)

2. **RECHERCHE INTELLIGENTE**:
   - Cherche les CONCEPTS, pas les mots exacts
   - Accepte les Ã‰QUIVALENTS et SYNONYMES
   - Exemple: "Python" inclut pandas, Django, Flask, FastAPI, etc.
   - Exemple: "SQL" inclut MySQL, PostgreSQL, Oracle, SQL Server, etc.
   - Exemple: "Bac+5" = Master = MSc = IngÃ©nieur = DiplÃ´me niveau 7 (STRICT, pas de flexibilitÃ©)

2bis. **PRÃ‰-FILTRE ATOMIQUE** (OBLIGATOIRE - vÃ©rification avant rÃ¨gle 2):
   - AVANT d'appliquer la recherche intelligente, identifie si le critÃ¨re est "atomique"
   - **CritÃ¨res atomiques** = mots-clÃ©s stricts, non-ambigus, outils/technos prÃ©cis
     Exemples: "Canva", "Figma", "Python", "AWS", "Kubernetes", "Excel", "PowerPoint"
   - **VÃ©rification BINAIRE** (prÃ©sent/absent):
     â€¢ Cherche le mot exact (insensible Ã  la casse) dans:
       - Section "competences_techniques" ou "outils" du CV
       - Descriptions d'expÃ©riences/projets
     â€¢ PAS d'Ã©quivalents acceptÃ©s pour les atomiques (ex: "Sketch" â‰  "Canva")
   - **Si atomique ABSENT** â†’ present=false + commentaire explicite: "CritÃ¨re atomique absent: [nom] non trouvÃ©"
   - **Si NON-atomique** â†’ Applique rÃ¨gle 2 (recherche intelligente avec Ã©quivalents)

3. **CALCUL DES ANNÃ‰ES D'EXPÃ‰RIENCE** (CRITIQUE):

   a) **Identification du domaine**:
      - Si critÃ¨re avec DOMAINE (ex: "5 ans en Data", "3 ans en Backend"):
        â†’ Identifie TOUTES les expÃ©riences du domaine + domaines PROCHES
        â†’ Exemples domaines proches:
          â€¢ "Data" inclut: Data Science, Data Analyst, ML Engineer, BI, Analytics, Big Data
          â€¢ "Backend" inclut: API Development, Microservices, Server-side, Architecture
          â€¢ "Frontend" inclut: UI/UX Development, React, Vue, Angular, Web client-side
        â†’ Additionne UNIQUEMENT ces expÃ©riences

      - Si critÃ¨re GÃ‰NÃ‰RAL (ex: "5 ans d'expÃ©rience", "3 ans minimum"):
        â†’ Additionne TOUTES les expÃ©riences professionnelles

   b) **Addition des durÃ©es** (IMPORTANT):
      - ADDITIONNE toutes les durÃ©es pertinentes, ne prends PAS que la plus longue
      - Exemple: 2 ans entreprise A + 1.5 ans entreprise B + 1 an entreprise C = 4.5 ans TOTAL
      - Convertis en annÃ©es dÃ©cimales (ex: "2 ans et 6 mois" = 2.5 ans)

   c) **FLEXIBILITÃ‰ sur le seuil** (marge de tolÃ©rance 15%):
      - Si Ã©cart â‰¤ 15% du seuil â†’ ACCEPTER avec mention
      - Exemples:
        â€¢ DemandÃ©: 5 ans â†’ Seuil mini: 4.25 ans (85% de 5) â†’ ACCEPTER dÃ¨s 4.25 ans
        â€¢ DemandÃ©: 3 ans â†’ Seuil mini: 2.55 ans (85% de 3) â†’ ACCEPTER dÃ¨s 2.55 ans
        â€¢ DemandÃ©: 10 ans â†’ Seuil mini: 8.5 ans (85% de 10) â†’ ACCEPTER dÃ¨s 8.5 ans

      - âš ï¸ Si flexibilitÃ© appliquÃ©e â†’ MENTIONNE-LE EXPLICITEMENT dans le "commentaire":
        Exemple: "4.5 ans d'expÃ©rience en Data (lÃ©gÃ¨rement sous les 5 ans, flexibilitÃ© appliquÃ©e)"

4. **DIPLÃ”MES** (STRICT, pas de flexibilitÃ©):
   - VÃ©rifie le NIVEAU Ã©quivalent exact
   - Accepte Ã©quivalences: Master = Bac+5 = MSc = IngÃ©nieur
   - PAS de flexibilitÃ©: Bac+4 â‰  Bac+5

5. **LANGUES**:
   - B2 = "courant", C1 = "bilingue", natif > B2
   - Analyse sÃ©mantique: "English fluent" = B2/C1

6. **PREUVES**:
   - Pour CHAQUE critÃ¨re vÃ©rifiÃ©, cite l'Ã‰LÃ‰MENT du CV qui le prouve
   - Si manquant, indique QUEL critÃ¨re bloque
   - Si flexibilitÃ© expÃ©rience appliquÃ©e, DÃ‰TAILLE le calcul dans le commentaire

ğŸ¯ FORMAT DE RÃ‰PONSE (JSON STRICT):
{{
  "decision": "ACCEPTÃ‰" | "Ã‰LIMINÃ‰",
  "criteres_verifies": [
    {{
      "critere": "nom du critÃ¨re",
      "present": true|false,
      "commentaire": "Explication complÃ¨te incluant: calcul dÃ©taillÃ© + preuves du CV + flexibilitÃ© si appliquÃ©e"
    }}
  ],
  "rationale": "SynthÃ¨se en 1 phrase: pourquoi acceptÃ©/Ã©liminÃ© (mentionne flexibilitÃ© si appliquÃ©e)",
  "element_declencheur": "Le critÃ¨re manquant qui bloque (ou null si acceptÃ©)"
}}

ğŸ“ EXEMPLES DE COMMENTAIRES (preuves INTÃ‰GRÃ‰ES dans commentaire):

Exemple 1 (avec flexibilitÃ©):
{{
  "critere": "5 ans d'expÃ©rience en Data",
  "present": true,
  "commentaire": "CritÃ¨re satisfait avec flexibilitÃ© (15%). Calcul: Data Analyst 2 ans (Capgemini 2019-2021) + Data Scientist 2.5 ans (BNP Paribas 2021-2023) = 4.5 ans total. LÃ©gÃ¨rement sous les 5 ans requis mais au-dessus du seuil minimal de 4.25 ans (85%)."
}}

Exemple 2 (sans flexibilitÃ©, OK):
{{
  "critere": "3 ans d'expÃ©rience",
  "present": true,
  "commentaire": "CritÃ¨re satisfait. Calcul: Dev Backend 2 ans (SociÃ©tÃ© A) + Dev Fullstack 1.5 ans (SociÃ©tÃ© B) = 3.5 ans d'expÃ©rience professionnelle totale."
}}

Exemple 3 (trop faible, rejetÃ©):
{{
  "critere": "5 ans d'expÃ©rience en Backend",
  "present": false,
  "commentaire": "CritÃ¨re NON satisfait. Calcul: Dev Backend 1.5 ans (Startup X) + Dev Fullstack (partie backend) 1.5 ans (Agence Y) = 3 ans total. En dessous du seuil minimal requis de 4.25 ans (85% de 5 ans)."
}}

Exemple 4 (compÃ©tence technique):
{{
  "critere": "Python",
  "present": true,
  "commentaire": "CritÃ¨re satisfait. Preuves: Section compÃ©tences techniques mentionne 'Python, pandas, Django, scikit-learn'. ConfirmÃ© par expÃ©riences en tant que Data Scientist utilisant Python quotidiennement."
}}

âš ï¸ IMPORTANT:
- Retourne UNIQUEMENT le JSON, pas de texte avant/aprÃ¨s
- Si UN SEUL critÃ¨re manque â†’ decision="Ã‰LIMINÃ‰" + element_declencheur renseignÃ©
- Si TOUS prÃ©sents â†’ decision="ACCEPTÃ‰" + element_declencheur=null
- Pour CHAQUE critÃ¨re d'expÃ©rience: DÃ‰TAILLE le calcul dans "commentaire" + mentionne flexibilitÃ© si appliquÃ©e
"""

        try:
            response = self.openai_client.chat.completions.create(
                model=self.llm_model,
                messages=[
                    {"role": "system", "content": "Tu es un expert RH. Tu rÃ©ponds UNIQUEMENT en JSON valide conforme au schÃ©ma demandÃ©."},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
                seed=self.seed,  # DÃ©terminisme: mÃªme seed = mÃªmes rÃ©sultats
                # GPT-5 mini: pas de paramÃ¨tre temperature
                timeout=timeout_s
            )

            result_text = response.choices[0].message.content.strip()
            result = json.loads(result_text)

            # Validation du format
            decision = result.get("decision", "Ã‰LIMINÃ‰")
            rationale = result.get("rationale", "RÃ©ponse LLM invalide")
            element_declencheur = result.get("element_declencheur")

            accepted = decision == "ACCEPTÃ‰"

            # Log compact
            if accepted:
                print(f"âœ… {cv_name}: ACCEPTÃ‰")
            else:
                print(f"âŒ {cv_name}: Ã‰LIMINÃ‰ (bloquÃ© par: {element_declencheur or 'non prÃ©cisÃ©'})")

            return accepted, rationale, result

        except json.JSONDecodeError as e:
            print(f"âš ï¸ {cv_name}: Erreur parsing JSON - {str(e)}")
            return False, f"Erreur parsing: {str(e)}", {"error": "json_decode", "raw": result_text if 'result_text' in locals() else ""}

        except Exception as e:
            print(f"âŒ {cv_name}: Erreur LLM - {str(e)}")
            return False, f"Erreur LLM: {str(e)}", {"error": str(e)}

    def check_single_cv_must_have_legacy(
        self,
        cv: Dict,
        indispensables: List[str],
        job_description: str
    ) -> bool:
        """
        ANCIENNE VERSION - ConservÃ©e pour compatibilitÃ©
        Retourne uniquement bool (acceptÃ©/rejetÃ©)
        """
        accepted, rationale, raw = self.check_single_cv_must_have(cv, indispensables, job_description)
        return accepted

    def filter_cvs_by_must_have(
        self,
        cvs: List[Dict],
        indispensables: List[str],
        job_description: str,
        use_parallel: bool = False,
        progress_callback=None
    ) -> List[Dict]:
        """
        Filtre les CVs selon les must-have indispensables

        Args:
            cvs: Liste des CVs
            indispensables: Liste des must-have indispensables
            job_description: Description de l'offre
            use_parallel: Si True, utilise la version parallÃ©lisÃ©e
            progress_callback: Callback(current, total) pour progression

        Returns:
            Liste des CVs acceptÃ©s
        """
        print(f"\nğŸ” FILTRAGE PAR MUST-HAVE INDISPENSABLES")
        print(f"CritÃ¨res indispensables: {len(indispensables)}")
        print(f"Mode: {'PARALLÃˆLE' if use_parallel else 'SÃ‰QUENTIEL'}")

        # VÃ©rification liste vide
        if not indispensables or all(not c.strip() for c in indispensables):
            print("âš ï¸ ATTENTION: Aucun critÃ¨re indispensable dÃ©fini â†’ TOUS les CVs sont acceptÃ©s")
            return list(cvs)  # Retourner tous les CVs sans filtrage

        if use_parallel:
            # Version parallÃ¨le
            try:
                from must_have_parallel import filter_cvs_by_must_have_parallel_sync

                # Configuration: forcer 500 max concurrent sans timeout
                concurrency = min(len(cvs), 500)
                qps = 100.0  # QPS Ã©levÃ© pour parallÃ©lisation rapide
                timeout_s = 300  # 5 minutes (appels LLM lents)
                retries = 1  # 1 seul retry
                backoff_s = 2.0

                accepted, rejected, traces = filter_cvs_by_must_have_parallel_sync(
                    cvs, indispensables, job_description,
                    decide_fn=self.check_single_cv_must_have,
                    concurrency=concurrency,
                    qps=qps,
                    timeout_s=timeout_s,
                    retries=retries,
                    backoff_s=backoff_s,
                    progress_callback=progress_callback
                )

                print(f"\nğŸ“Š {len(accepted)} CVs acceptÃ©s sur {len(cvs)}")
                return accepted

            except ImportError:
                print("âš ï¸ Module must_have_parallel non trouvÃ©, basculement en mode sÃ©quentiel")
                use_parallel = False

        # Version sÃ©quentielle (fallback ou par dÃ©faut)
        cvs_acceptes = []
        total = len(cvs)

        for idx, cv in enumerate(cvs):
            if progress_callback:
                progress_callback(idx + 1, total)

            accepted, rationale, raw = self.check_single_cv_must_have(cv, indispensables, job_description)
            if accepted:
                cvs_acceptes.append(cv)

        print(f"\nğŸ“Š {len(cvs_acceptes)} CVs acceptÃ©s sur {len(cvs)}")
        return cvs_acceptes

    def _old_filter_cvs_by_must_have_v1(
        self,
        cvs: List[Dict],
        indispensables: List[str],
        job_description: str
    ) -> List[Dict]:
        """
        ANCIENNE VERSION - GardÃ©e pour rÃ©fÃ©rence
        """
        cvs_acceptes = []

        print(f"\nğŸ” FILTRAGE PAR MUST-HAVE INDISPENSABLES")
        print(f"CritÃ¨res indispensables: {len(indispensables)}")

        for i, cv in enumerate(cvs):
            cv_name = cv.get("cv", f"cv_{i}")

            # Liste numÃ©rotÃ©e des critÃ¨res
            criteres_liste = "\n".join([f"{j+1}. {critere}" for j, critere in enumerate(indispensables)])

            prompt = f"""
            Tu es un expert RH avec une expertise approfondie en analyse de CVs et recrutement.

            CONTEXTE DE L'OFFRE :
            {job_description}

            CRITÃˆRES INDISPENSABLES Ã€ VÃ‰RIFIER (UNIQUEMENT CES CRITÃˆRES) :
            {criteres_liste}

            IMPORTANT : Tu ne dois vÃ©rifier QUE ces {len(indispensables)} critÃ¨res indispensables.

            CV Ã€ ANALYSER :
            {json.dumps(cv, ensure_ascii=False, indent=2)}

            RÃˆGLES D'ANALYSE :
            - Sois INTELLIGENT et CONTEXTUEL, pas littÃ©ral
            - Cherche des CONCEPTS, pas des mots exacts
            - Accepte les Ã‰QUIVALENTS et SYNONYMES
            - Comprends les VARIATIONS de formulation

            RÃˆGLES SPÃ‰CIALES :
            - **DIPLÃ”MES** : Master = Bac+5, MSc = Master, Licence = Bac+3, etc.
            - **COMPÃ‰TENCES** : "Python" inclut pandas, numpy, Django, etc. | "SQL" inclut MySQL, PostgreSQL, etc.
            - **LANGUES** : "FranÃ§ais" = natif, courant, maternelle | "Anglais" = English, courant, B2, C1, etc.
            - **DOMAINES** : "Data Science" = Machine Learning = IA = Analytics = Big Data
            - **EXPÃ‰RIENCE** : Sois PRÃ‰CIS sur les durÃ©es - additionne TOUTES les expÃ©riences pertinentes

            VÃ©rifie CHAQUE critÃ¨re indispensable un par un. Si UN SEUL critÃ¨re manque = Ã‰LIMINATION.

            RÃ©ponds UNIQUEMENT par :
            - "ACCEPTÃ‰" si TOUS les critÃ¨res indispensables sont prÃ©sents
            - "Ã‰LIMINÃ‰" si UN SEUL critÃ¨re indispensable manque

            Ajoute une ligne avec la liste des critÃ¨res indispensables manquants ou une confirmation.
            """

            response = self.openai_client.chat.completions.create(
                model=self.llm_model,
                messages=[
                    {"role": "system", "content": f"Tu es un expert RH avec intelligence contextuelle. Tu vÃ©rifies UNIQUEMENT les {len(indispensables)} critÃ¨res indispensables donnÃ©s."},
                    {"role": "user", "content": prompt}
                ],
                seed=self.seed  # DÃ©terminisme: mÃªme seed = mÃªmes rÃ©sultats
            )

            decision = response.choices[0].message.content.strip()
            print(f"ğŸ“„ {cv_name} : {decision[:100]}...")

            if decision.startswith("ACCEPTÃ‰"):
                cvs_acceptes.append(cv)

        print(f"\nğŸ“Š {len(cvs_acceptes)} CVs acceptÃ©s sur {len(cvs)}")
        return cvs_acceptes

    def compute_similarity_with_scoring(
        self,
        job_text: str,
        cvs: List[Dict],
        nice_have_list: List[str],
        job_description: str,
        progress_callback=None
    ) -> List[Dict]:
        """
        Calcule la similaritÃ© + scoring nice-have + bonus expÃ©riences (VERSION OPTIMISÃ‰E BATCH)

        Args:
            job_text: Texte de l'offre aplati
            cvs: Liste des CVs filtrÃ©s
            nice_have_list: Liste des nice-have
            job_description: Description complÃ¨te de l'offre
            progress_callback: Fonction callback(current, total) pour suivre la progression

        Returns:
            Liste des Top-K CVs avec scores
        """
        import time

        print(f"\nğŸ“Š CALCUL DE SIMILARITÃ‰ sur {len(cvs)} CVs (mode BATCH optimisÃ©)")

        # === Ã‰TAPE 1: Encoder l'offre (1 seule fois, normalisÃ©) ===
        t0 = time.perf_counter()
        job_vec = self.embedding_model.encode(
            [job_text],
            batch_size=1,
            convert_to_numpy=True,
            normalize_embeddings=True,
            show_progress_bar=False
        ).astype(np.float32)  # Shape: (1, d)
        t1 = time.perf_counter()

        # === Ã‰TAPE 2: Encoder tous les CVs en batch ===
        cv_texts = [self._flatten_cv_text(cv) for cv in cvs]

        # Debug: vÃ©rifier que les CVs ne sont pas vides
        cv_lengths = [len(parts) for parts in cv_texts]
        print(f"[DEBUG] CV texts lengths: min={min(cv_lengths)}, max={max(cv_lengths)}, mean={sum(cv_lengths)/len(cv_lengths):.1f}")
        if min(cv_lengths) == 0:
            print(f"[WARNING] {sum(1 for l in cv_lengths if l == 0)} CVs ont des textes vides!")

        cv_matrix = self.vectorize_many_docs(cv_texts, normalize=True)  # Shape: (N, d)
        t2 = time.perf_counter()

        # === Ã‰TAPE 3: Calcul vectorisÃ© des cosines (dot product car normalisÃ©) ===
        # Debug shapes
        print(f"[DEBUG] job_vec.shape={job_vec.shape}, cv_matrix.shape={cv_matrix.shape}")

        sims = (cv_matrix @ job_vec.T).ravel()  # Shape: (N,)
        t3 = time.perf_counter()

        # Debug scores
        print(f"[DEBUG] sims min={sims.min():.4f}, max={sims.max():.4f}, mean={sims.mean():.4f}")
        print(f"[DEBUG] Premiers scores: {sims[:5]}")

        print(f"[TIMINGS] encode_offre={t1-t0:.3f}s | encode_CV_batch={t2-t1:.3f}s | cosines_matmul={t3-t2:.3f}s | TOTAL={t3-t0:.3f}s")

        # === Ã‰TAPE 4: Recherche nice-have manquants EN PARALLÃˆLE ===
        t4 = time.perf_counter()
        nice_have_map = {}

        if nice_have_list and any(s.strip() for s in nice_have_list):
            # Version parallÃ©lisÃ©e
            try:
                from nice_have_parallel import find_nice_have_missing_parallel_sync

                # Configuration: forcer 500 max concurrent sans timeout
                concurrency = min(len(cvs), 500)
                qps = 10.0
                timeout_s = 300  # 5 minutes (appels LLM lents)
                retries = 1
                backoff_s = 2.0

                nice_have_map = find_nice_have_missing_parallel_sync(
                    cvs, nice_have_list, job_description,
                    find_fn=self._find_nice_have_missing,
                    concurrency=concurrency,
                    qps=qps,
                    timeout_s=timeout_s,
                    retries=retries,
                    backoff_s=backoff_s,
                    progress_callback=progress_callback
                )

            except ImportError:
                print("âš ï¸ Module nice_have_parallel non trouvÃ©, basculement en mode sÃ©quentiel")
                # Fallback sÃ©quentiel
                for idx, cv in enumerate(cvs):
                    if progress_callback:
                        progress_callback(idx + 1, len(cvs))
                    cv_id = cv.get("cv", f"cv_{idx}")
                    nice_have_map[cv_id] = self._find_nice_have_missing(cv, nice_have_list, job_description)

        t5 = time.perf_counter()
        print(f"[TIMINGS] nice_have_detection={'PARALLÃˆLE' if 'nice_have_parallel' in str(type(nice_have_map)) else 'sÃ©quentiel'}={t5-t4:.3f}s")

        # === Ã‰TAPE 5: Calcul des scores finaux ===
        scores = []

        for idx, cv in enumerate(cvs):
            # RÃ©cupÃ©rer la similaritÃ© prÃ©-calculÃ©e
            sim_base = float(sims[idx])

            # RÃ©cupÃ©rer les nice-have manquants (dÃ©jÃ  calculÃ©s en parallÃ¨le)
            cv_id = cv.get("cv", f"cv_{idx}")
            nice_have_manquants = nice_have_map.get(cv_id, [])

            # Bonus MULTIPLICATEUR pour nice-have prÃ©sents (rÃ©duction si absents: 0.95 par compÃ©tence manquante)
            nombre_manquants = len(nice_have_manquants)
            bonus_factor = self.scoring_config.get("nice_have_malus_factor", 0.95)
            bonus_nice_have_multiplicateur = bonus_factor ** nombre_manquants if nombre_manquants > 0 else 1.0

            # Score final = score_base Ã— bonus_nice_have
            score_final = sim_base * bonus_nice_have_multiplicateur
            score_final = max(0.0, min(1.0, score_final))

            scores.append({
                "cv": cv.get("cv", "inconnu"),
                "score_base": float(sim_base),
                "score_final": float(score_final),
                "bonus_nice_have_multiplicateur": float(bonus_nice_have_multiplicateur),
                "nice_have_manquants": nice_have_manquants,
                "nombre_manquants": nombre_manquants,
                "content": cv
            })

        # Trier tous les CVs par score (pas de limite top_k, c'est fait au re-ranking)
        sorted_scores = sorted(scores, key=lambda x: x["score_final"], reverse=True)

        return sorted_scores

    def rerank_with_llm(self, top_cvs: List[Dict], job_description: str, progress_callback=None, top_n: int = None) -> List[Dict]:
        """
        Re-ranking LLM du top-N avec prompt alignÃ© et fallback robuste

        Args:
            top_cvs: Top CVs Ã  re-ranker
            job_description: Description de l'offre
            progress_callback: Fonction callback(current, total) pour suivre la progression
            top_n: Nombre de CVs Ã  re-ranker (override config si fourni)

        Returns:
            CVs re-rankÃ©s avec commentaires
        """
        # Si top_n fourni en paramÃ¨tre, on l'utilise ; sinon on prend la config
        if top_n is not None:
            cvs_to_rerank = top_cvs[:top_n]
        else:
            top_rerank = self.scoring_config.get("top_rerank", 10)
            cvs_to_rerank = top_cvs[:top_rerank]

        print(f"\nğŸ† RE-RANKING LLM sur {len(cvs_to_rerank)} CVs")

        if progress_callback:
            progress_callback(0, len(cvs_to_rerank))

        # Extraire les noms de CVs pour les forcer dans le prompt
        cv_names = [cv.get('cv', 'inconnu') for cv in cvs_to_rerank]

        # CrÃ©er un rÃ©sumÃ© enrichi des CVs avec tous les dÃ©tails de scoring
        cv_summaries = []
        for i, cv in enumerate(cvs_to_rerank, 1):
            cv_name = cv.get('cv', 'inconnu')
            score_base = cv.get('score_base', 0.0)
            score_final = cv.get('score_final', 0.0)
            bonus_nice_have = cv.get('bonus_nice_have_multiplicateur', 1.0)
            nice_have_manquants = cv.get('nice_have_manquants', [])
            cv_content = cv.get('content', {})

            # Extraire le contenu COMPLET du CV (pas de troncation)
            if isinstance(cv_content, dict):
                sections = cv_content.get('sections', cv_content)

                identite = sections.get('identite', {}) if isinstance(sections, dict) else {}
                candidate_first_name = (identite.get('prenom') or '').strip()
                candidate_last_name = (identite.get('nom') or '').strip()
                candidate_name = f"{candidate_first_name} {candidate_last_name}".strip() or cv_name

                # DÃ©tecter les flags (gappes & overlaps) sur TOUTES les expÃ©riences
                all_experiences = sections.get('experiences_professionnelles', []) if isinstance(sections.get('experiences_professionnelles'), list) else []
                from lib.experience_analyzer import detect_gaps_and_overlaps as detect_gaps, format_flags_for_llm as format_flags
                flags = detect_gaps(all_experiences)
                flags_summary = format_flags(flags)

                # Calculer les nice-have prÃ©sents (tous sauf manquants)
                all_nice_have = set(nice_have_list) if 'nice_have_list' in locals() else set()
                nice_have_presents = list(all_nice_have - set(nice_have_manquants)) if all_nice_have else []

                cv_summaries.append({
                    "position": i,
                    "nom_fichier": cv_name,
                    "score_base": round(score_base, 3),
                    "score_final": round(score_final, 3),
                    "bonus_nice_have_multiplicateur": round(bonus_nice_have, 3),
                    "nice_have_presents": nice_have_presents,
                    "nice_have_absents": nice_have_manquants,
                    "nombre_nice_have_presents": len(nice_have_presents),
                    "nombre_nice_have_absents": len(nice_have_manquants),
                    "contenu_complet": sections,  # âœ… Tout le CV, pas juste 2 expÃ©riences + 5 compÃ©tences
                    "candidate_name": candidate_name,
                    "flags": flags_summary,  # Flags formatÃ©s pour le LLM
                    "flags_raw": {  # Flags bruts pour rÃ©cupÃ©ration ultÃ©rieure
                        "gappes": [{"period": g.period, "duration_months": g.duration_months, "between": g.between} for g in flags.gappes],
                        "overlaps": [{"overlap_period": o.overlap_period, "overlap_days": o.overlap_days, "experiences": o.experiences, "same_company": o.same_company} for o in flags.overlaps]
                    }
                })

        prompt = f"""Tu es un expert RH senior avec 15 ans d'expÃ©rience en recrutement tech.

OFFRE D'EMPLOI COMPLÃˆTE:
{job_description}

CVS Ã€ RE-CLASSER (du meilleur au moins bon):
{json.dumps(cv_summaries, ensure_ascii=False, indent=2)}

SYSTÃˆME DE SCORING (pour ta comprÃ©hension):
- Score base: SimilaritÃ© sÃ©mantique CV/Offre (0.0 Ã  1.0) calculÃ©e par embedding
- Bonus nice-have: Multiplicateur appliquÃ© selon les nice-have prÃ©sents (formule: 0.95^nb_absents)
- Score final = score_base Ã— bonus_nice_have

âš ï¸ IMPORTANT: Le score final ne prend PAS en compte l'analyse qualitative des expÃ©riences.
C'est TON rÃ´le d'expert RH de les analyser et de re-classer les CVs en consÃ©quence.

TA MISSION:
1. Analyse COMPARATIVEMENT les expÃ©riences professionnelles de chaque candidat :
   - DurÃ©e et pertinence des expÃ©riences par rapport au poste
   - QualitÃ© des environnements de travail (startup, grande entreprise, international, etc.)
   - CohÃ©rence et progression du parcours
   - Missions et responsabilitÃ©s en lien avec l'offre

2. Re-classe ces {len(cvs_to_rerank)} CVs du MEILLEUR au MOINS BON en tenant compte de :
   - Le score quantitatif (base + nice-have)
   - TON analyse qualitative des expÃ©riences (facteur discriminant principal)
   - L'adÃ©quation globale du profil

3. Pour CHAQUE CV, rÃ©dige 2 commentaires distincts et dÃ©taillÃ©s

FORMAT JSON OBLIGATOIRE:
{{
  "ranked_cvs": [
    {{
      "cv": "COPIE_EXACTE_NOM_FICHIER.json",
      "coefficient_qualite_experience": 1.0,
      "commentaire_scoring": "2-3 lignes avec rÃ©fÃ©rences [E1], [E2]...",
      "appreciation_globale": "6-7 lignes avec rÃ©fÃ©rences [E1], [E3]...",
      "evidences": [
        {{"id": "E1", "type": "section", "ref": "ExpÃ©rience #2 â€“ DevOps @ Foo â€“ Missions"}},
        {{"id": "E2", "type": "quote", "ref": "5 ans d'expertise Kubernetes en production"}},
        ...
      ],
      "evidence_map": {{
        "commentaire_scoring": ["E1", "E2"],
        "appreciation_globale": ["E1", "E3"]
      }}
    }},
    ...
  ]
}}

âš ï¸ RÃˆGLES POUR LES Ã‰VIDENCES (CRITIQUE):
âœ“ Pour chaque affirmation dans tes commentaires, ajoute une rÃ©fÃ©rence [E1], [E2], etc.
âœ“ CrÃ©e une evidence pour chaque rÃ©fÃ©rence avec:
  - id: identifiant unique ("E1", "E2", etc.)
  - type: "section" (repÃ¨re humain), "json_path" (chemin technique), ou "quote" (citation â‰¤12 mots)
  - ref: le contenu de la rÃ©fÃ©rence
âœ“ RÃ©utilise les mÃªmes evidences pour plusieurs phrases si appropriÃ©
âœ“ Dans evidence_map, liste les IDs utilisÃ©s par chaque commentaire

EXEMPLES D'Ã‰VIDENCES:
- {{"id": "E1", "type": "section", "ref": "ExpÃ©rience #2 â€“ Architecte Data @ Banque â€“ 4 ans"}}
- {{"id": "E2", "type": "quote", "ref": "TOGAF certifiÃ©, pilotage CODIR"}}
- {{"id": "E3", "type": "json_path", "ref": "experiences[1].missions[3]"}}
- {{"id": "E4", "type": "section", "ref": "Trou de 6 mois entre Exp #2 et #3"}}

INSTRUCTIONS POUR "commentaire_scoring" (2-3 lignes, style technique et factuel):
âœ“ Explique les Ã©lÃ©ments du score: score de base et bonus nice-have
âœ“ **CRITIQUE**: Mentionne EXPLICITEMENT les nice-have MANQUANTS s'il y en a (liste exhaustive)
âœ“ Si nice-have manquants â†’ explique l'impact sur le multiplicateur (0.95^nb_manquants)
âœ“ **IMPORTANT**: Ajoute au moins 1-2 rÃ©fÃ©rences [E#] pour justifier le score ou les compÃ©tences clÃ©s
âœ“ Ton professionnel, concis, orientÃ© chiffres et justifications claires
âœ“ EXEMPLE avec manquants: "Score base de 0.75 reflÃ©tant une bonne adÃ©quation technique [E1]. Multiplicateur de 0.9025 (Ã—0.95Â²) appliquÃ© en raison de 2 nice-have manquants : Kubernetes et CI/CD avancÃ©. Score final: 0.68."
âœ“ EXEMPLE sans manquants: "Score base de 0.80 avec excellente couverture technique [E2]. Multiplicateur optimal de 1.00 (tous les nice-have prÃ©sents : Docker, Python avancÃ©, PostgreSQL [E3]). Score final: 0.80."

INSTRUCTIONS POUR "coefficient_qualite_experience" (nombre dÃ©cimal entre 1.0 et 1.4):
âœ“ **CRITIQUE**: Ã‰value la qualitÃ© et pertinence des EXPÃ‰RIENCES professionnelles
âœ“ **ESSENTIEL**: Attribue un coefficient selon cette grille STRICTE:
  â€¢ 1.4 : ExpÃ©rience EXCEPTIONNELLE (leadership technique, projets majeurs, environnement identique)
  â€¢ 1.3 : ExpÃ©rience TRÃˆS FORTE (senior, projets complexes, trÃ¨s grande pertinence)
  â€¢ 1.2 : ExpÃ©rience FORTE (confirmÃ©, bonne pertinence, environnement proche)
  â€¢ 1.1 : ExpÃ©rience PERTINENTE (standard pour le poste, domaine connexe)
  â€¢ 1.0 : ExpÃ©rience CORRECTE (junior ou peu pertinent pour le poste spÃ©cifique)
âœ“ Ce coefficient sera multipliÃ© au score pour le calcul final

INSTRUCTIONS POUR "appreciation_globale" (6-7 lignes, style RH expert et qualitatif):
âœ“ **CRITIQUE**: Analyse EN PROFONDEUR la qualitÃ© et pertinence des EXPÃ‰RIENCES professionnelles
âœ“ Justifie le coefficient attribuÃ© en comparant les expÃ©riences entre candidats
âœ“ Compare les expÃ©riences entre candidats (durÃ©e, environnement, missions, progression)
âœ“ Ã‰value l'adÃ©quation globale du profil au poste recherchÃ©
âœ“ Identifie les 2-3 forces principales du candidat par rapport au poste
âœ“ **IMPORTANT**: Mentionne les DRAPEAUX DE VIGILANCE si prÃ©sents (trous, chevauchements)
  - Trous â‰¥3 mois : Signale et demande clarification
  - Chevauchements >14 jours : Note et questionne si nÃ©cessaire
âœ“ Donne une recommandation RH claire et actionnable (Fortement recommandÃ© / RecommandÃ© / Ã€ considÃ©rer)
âœ“ Ton professionnel, humain, orientÃ© dÃ©cision de recrutement
âœ“ Ajoute des rÃ©fÃ©rences d'evidences [E1], [E2]... pour justifier tes affirmations
âœ“ Commence toujours l'apprÃ©ciation par le nom complet du candidat (champ "candidate_name") pour faciliter la lecture.

âœ“ EXEMPLE profil senior: "Profil exceptionnel pour ce poste de DÃ©veloppeur Backend Senior (coefficient: 1.4). Le candidat possÃ¨de 7 ans d'expÃ©rience progressive en environnement agile, dont 4 ans en tant que lead technique sur des architectures microservices complexes chez Amazon. Cette expÃ©rience de leadership technique dans un environnement identique est un diffÃ©renciateur majeur par rapport aux autres candidats. Sa maÃ®trise du stack Python/Django et son expertise dÃ©montrÃ©e en CI/CD + Kubernetes rÃ©pondent parfaitement aux besoins. Fortement recommandÃ© pour entretien technique approfondi."

âœ“ EXEMPLE profil confirmÃ©: "Profil solide pour ce poste de DÃ©veloppeur Backend (coefficient: 1.2). Le candidat possÃ¨de 4 ans d'expÃ©rience en architecture microservices avec une bonne maÃ®trise du stack Python/Django. Son parcours dans des ESN lui a permis de toucher Ã  des environnements variÃ©s. Seule vigilance : absence de Kubernetes, mais compensable par formation rapide vu sa capacitÃ© d'apprentissage dÃ©montrÃ©e. RecommandÃ© pour un entretien technique."

âœ“ EXEMPLE profil junior: "Profil junior correct pour ce poste (coefficient: 1.0). Le candidat possÃ¨de 2 ans d'expÃ©rience en dÃ©veloppement backend, principalement sur des projets de taille moyenne. Les compÃ©tences techniques sont prÃ©sentes mais manquent de profondeur et d'exposition Ã  des architectures complexes. L'expÃ©rience est un peu juste pour le niveau senior attendu. Ã€ considÃ©rer si ouverture Ã  un profil confirmÃ© plutÃ´t que senior."

NOMS DE FICHIERS Ã€ UTILISER (COPIE EXACTE - CRITIQUE):
{json.dumps(cv_names, ensure_ascii=False)}

âš ï¸ RÃˆGLES ABSOLUES:
- Utilise EXACTEMENT les noms de fichiers ci-dessus (copie-colle)
- Ne recalcule PAS les scores, utilise-les pour ta comprÃ©hension
- RÃ©ponds UNIQUEMENT en JSON valide, sans texte avant/aprÃ¨s
- Respecte les longueurs: 2-3 lignes pour scoring, 6-7 lignes pour apprÃ©ciation

STABILITÃ‰ â€” ATTRIBUTION DU COEFFICIENT (INTERNE, SANS CHANGER LA SORTIE)

RÃ¨gles gÃ©nÃ©rales
- Tu ne classes pas les CV. Tu fournis uniquement la valeur du champ existant `coefficient_qualite_experience` âˆˆ {{1.0, 1.1, 1.2, 1.3, 1.4}}.
- Tu n'ajoutes, ne retires, ni ne modifies aucun autre champ du format de sortie.
- Cette section dÃ©crit uniquement la mÃ©thode interne d'attribution du coefficient. Tu DOIS toujours fournir les evidences dans le format JSON comme demandÃ© prÃ©cÃ©demment.

ProcÃ©dure interne (simple, dÃ©terministe, non rendue)
1) Identifie les exigences cÅ“ur de l'offre (missions/compÃ©tences rÃ©ellement attendues).
2) Ã‰value la CORRESPONDANCE DES MISSIONS (CM) du CV avec ces exigences :
   - STRONG  : couverture Ã©levÃ©e et missions trÃ¨s proches de l'offre
   - MEDIUM  : couverture correcte et missions globalement proches
   - WEAK    : couverture partielle et missions peu proches
   - MINIMAL : couverture faible
3) Estime les ANNÃ‰ES PERTINENTES (AP) : somme approximative des pÃ©riodes oÃ¹ les missions du CV correspondent aux exigences cÅ“ur.
   - Ignore trous/chevauchements ; arrondis Ã  0.5 an prÃ¨s ; reste factuel.

Attribution du coefficient (discret, stable)
- DÃ©termine une base par CM :
    MINIMAL â†’ 1.0
    WEAK    â†’ 1.1
    MEDIUM  â†’ 1.2
    STRONG  â†’ 1.3
- Ajuste selon AP :
    AP â‰¥ 6 ans   â†’ +0.1   (cap Ã  1.4)
    1 â‰¤ AP < 6   â†’ +0.0
    AP < 1 an    â†’ âˆ’0.1   (plancher 1.0)
- Garde-fous :
    â€¢ Si CM < MEDIUM, coefficient â‰¤ 1.2.
    â€¢ 1.4 uniquement si (CM = STRONG) et (AP â‰¥ 6 ans).
- En cas d'hÃ©sitation entre deux valeurs adjacentes, choisis la plus basse (principe de stabilitÃ©).

Consignes de cohÃ©rence
- Applique exactement ces seuils Ã  chaque rÃ©ponse ; ne rÃ©-Ã©talonne pas la barre d'une rÃ©ponse Ã  l'autre.
- Ne recalculle pas `score_base`/`bonus_nicehave`. Tu ne fournis ici que `coefficient_qualite_experience` dans le champ prÃ©vu par le format actuel.
""".strip()

        # === ROUTING PROVIDER ===
        provider = self.scoring_config.get("reranking_provider", "openai").lower()
        print(f"ğŸ”€ Provider reranking: {provider}")

        try:
            if provider == "xai":
                return self._rerank_with_xai(
                    cvs_to_rerank=cvs_to_rerank,
                    cv_summaries=cv_summaries,
                    prompt=prompt,
                    cv_names=cv_names,
                    progress_callback=progress_callback
                )
            else:  # default: openai
                return self._rerank_with_openai(
                    cvs_to_rerank=cvs_to_rerank,
                    cv_summaries=cv_summaries,
                    prompt=prompt,
                    cv_names=cv_names,
                    progress_callback=progress_callback
                )

        except Exception as e:
            # === FALLBACK ===
            import traceback
            print(f"âŒ Exception rerank: {e} â†’ fallback avec donnÃ©es prÃ©servÃ©es")
            print(f"   Traceback: {traceback.format_exc()[:200]}...")

            # Trier par score_final (donnÃ©es de base prÃ©servÃ©es)
            normalized_result = sorted(
                cvs_to_rerank, key=lambda x: x.get("score_final", 0.0), reverse=True
            )

            # Construire le fallback en PRÃ‰SERVANT les donnÃ©es de base
            fallback_results = []
            for s in normalized_result:
                cv_name = s.get("cv") or s.get("cv_id", "inconnu")

                # RÃ©cupÃ©rer les flags automatiques s'ils existent
                cv_content = s.get("content", {})
                flags_raw = None

                # DÃ©tecter les flags pour ce CV si possible
                if isinstance(cv_content, dict):
                    sections = cv_content.get('sections', cv_content)
                    all_experiences = sections.get('experiences_professionnelles', []) if isinstance(sections.get('experiences_professionnelles'), list) else []
                    if all_experiences:
                        from lib.experience_analyzer import detect_gaps_and_overlaps as detect_gaps_fallback
                        flags_detected = detect_gaps_fallback(all_experiences)
                        flags_raw = {
                            "gappes": [{"period": g.period, "duration_months": g.duration_months, "between": g.between} for g in flags_detected.gappes],
                            "overlaps": [{"overlap_period": o.overlap_period, "overlap_days": o.overlap_days, "experiences": o.experiences, "same_company": o.same_company} for o in flags_detected.overlaps]
                        }

                fallback_results.append({
                    "cv": cv_name,
                    "coefficient_qualite_experience": 1.0,  # Neutre (pas d'analyse LLM)
                    "commentaire_scoring": (
                        f"âš ï¸ Re-ranking LLM indisponible (erreur: {str(e)[:100]}). "
                        f"Score base: {s.get('score_base', 0.0):.3f}, "
                        f"Bonus nice-have: {s.get('bonus_nice_have_multiplicateur', 1.0):.3f}, "
                        f"Score final: {s.get('score_final', 0.0):.3f}. "
                        f"Tri automatique par score final (coefficient neutre appliquÃ©)."
                    ),
                    "appreciation_globale": (
                        "Analyse qualitative indisponible suite Ã  une erreur du service de reranking LLM. "
                        "Les scores quantitatifs (embeddings + nice-have) sont valides. "
                        "Coefficient qualitÃ© fixÃ© Ã  1.0 (neutre) en l'absence d'analyse RH automatisÃ©e. "
                        "Recommandation : Effectuer une analyse manuelle du CV ou relancer le matching."
                    ),
                    "evidences": [],  # Pas d'evidences sans LLM
                    "evidence_map": {},  # âœ… Normaliser None â†’ {}
                    "flags_raw": flags_raw or {}  # âœ… Normaliser None â†’ {}
                })

            print(f"âœ… Fallback: {len(fallback_results)} CVs retournÃ©s avec donnÃ©es prÃ©servÃ©es")
            return fallback_results

    def _rerank_with_openai(self, cvs_to_rerank, cv_summaries, prompt, cv_names, progress_callback=None):
        """
        Re-ranking avec OpenAI (mÃ©thode extraite)
        """
        response = self.openai_client.chat.completions.create(
            model=self.llm_model,
            messages=[
                {"role": "system", "content": "Tu rÃ©ponds UNIQUEMENT en JSON valide conforme au schÃ©ma demandÃ©."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"},
            seed=self.seed  # DÃ©terminisme: mÃªme seed = mÃªmes rÃ©sultats
        )

        raw_content = response.choices[0].message.content
        print(f"[DEBUG OpenAI] RÃ©ponse brute (premiers 500 chars): {raw_content[:500]}")

        result = self._safe_json_parse(raw_content)

        # Valider le schÃ©ma
        if not result or "ranked_cvs" not in result:
            raise ValueError(f"RÃ©ponse LLM invalide (pas de clÃ© 'ranked_cvs'): {result}")

        ranked_cvs_data = result.get("ranked_cvs", [])

        # DEBUG: Log ce que le LLM retourne
        print(f"[DEBUG OpenAI] Type ranked_cvs_data: {type(ranked_cvs_data)}")
        print(f"[DEBUG OpenAI] Nombre d'items: {len(ranked_cvs_data)}")
        print(f"[DEBUG OpenAI] Types des items: {[type(item) for item in ranked_cvs_data[:5]]}")

        # FILTRER les items invalides (None, scalaires, non-dict)
        ranked_cvs_valid = [cv for cv in ranked_cvs_data if isinstance(cv, dict)]
        if len(ranked_cvs_valid) != len(ranked_cvs_data):
            invalid_count = len(ranked_cvs_data) - len(ranked_cvs_valid)
            print(f"âš ï¸ [OpenAI] {invalid_count} items invalides ignorÃ©s dans ranked_cvs")
            print(f"   Items invalides: {[cv for cv in ranked_cvs_data if not isinstance(cv, dict)][:3]}")

        if not ranked_cvs_valid:
            raise ValueError(f"Aucun CV valide dans ranked_cvs (tous null/invalides). Total items: {len(ranked_cvs_data)}")

        # Enrichir avec coefficient, evidences et flags
        cv_map_by_name = {cv.get('cv'): cv for cv in cvs_to_rerank}
        cv_summaries_by_name = {s['nom_fichier']: s for s in cv_summaries}

        enriched_result = []
        for reranked_cv in ranked_cvs_valid:  # âœ… Utiliser la liste filtrÃ©e
            cv_name = reranked_cv.get("cv", "inconnu")
            summary = cv_summaries_by_name.get(cv_name, {})
            candidate_name = summary.get("candidate_name") or cv_name

            # NORMALISER les valeurs null retournÃ©es par le LLM
            evidences = reranked_cv.get("evidences") or []
            evidence_map = reranked_cv.get("evidence_map") or {}
            flags_raw = summary.get("flags_raw") or {}

            enriched_result.append({
                "cv": cv_name,
                "candidate_name": candidate_name,
                "coefficient_qualite_experience": reranked_cv.get("coefficient_qualite_experience", 1.0),
                "commentaire_scoring": reranked_cv.get("commentaire_scoring", ""),
                "appreciation_globale": reranked_cv.get("appreciation_globale", ""),
                "evidences": evidences,
                "evidence_map": evidence_map,
                "flags_raw": flags_raw
            })

        print(f"âœ… Re-ranking OpenAI: {len(enriched_result)} CVs retournÃ©s")
        return enriched_result

    def _call_xai_with_retry(self, payload):
        """
        Appel xAI avec retry automatique
        """
        XAI_BASE = "https://api.x.ai/v1"

        @retry(
            stop=stop_after_attempt(3),
            wait=wait_exponential(multiplier=1, min=2, max=10),
            retry=retry_if_exception_type((requests.exceptions.RequestException, requests.exceptions.Timeout))
        )
        def _do_call():
            api_key = os.environ.get('XAI_API_KEY')
            if not api_key:
                raise ValueError("XAI_API_KEY non trouvÃ©e dans l'environnement")

            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }

            resp = requests.post(
                f"{XAI_BASE}/chat/completions",
                json=payload,
                headers=headers,
                timeout=90
            )
            resp.raise_for_status()
            return resp.json()

        return _do_call()

    def _rerank_with_xai(self, cvs_to_rerank, cv_summaries, prompt, cv_names, progress_callback=None):
        """
        Re-ranking avec xAI (Grok-4-fast-reasoning)
        """
        XAI_MODEL = "grok-4-fast-reasoning"

        # Log du modÃ¨le utilisÃ©
        print(f"ğŸ¤– ModÃ¨le xAI utilisÃ©: {XAI_MODEL}")

        # Construire le payload (format OpenAI-compatible)
        payload = {
            "model": XAI_MODEL,
            "messages": [
                {"role": "system", "content": "Tu rÃ©ponds UNIQUEMENT en JSON valide conforme au schÃ©ma demandÃ©."},
                {"role": "user", "content": prompt}
            ],
            "response_format": {"type": "json_object"},
            "temperature": 0.15,
            "seed": self.seed,  # DÃ©terminisme: mÃªme seed = mÃªmes rÃ©sultats
            "max_tokens": 8000,  # AugmentÃ© pour re-ranker 10 CVs avec dÃ©tails
            "stream": False
        }

        # Appel xAI avec retry
        response_json = self._call_xai_with_retry(payload)

        # Parser la rÃ©ponse (format OpenAI-compatible)
        if "choices" not in response_json or len(response_json["choices"]) == 0:
            raise ValueError(f"RÃ©ponse xAI invalide: {response_json}")

        raw_content = response_json["choices"][0]["message"]["content"]
        print(f"[DEBUG xAI] RÃ©ponse brute (premiers 500 chars): {raw_content[:500]}")

        result = self._safe_json_parse(raw_content)

        # Grok peut retourner soit un objet {"ranked_cvs": [...]}, soit directement un array [...]
        if isinstance(result, list):
            print(f"[DEBUG xAI] Grok a retournÃ© directement un array (non-standard)")
            ranked_cvs_data = result
        elif isinstance(result, dict) and "ranked_cvs" in result:
            ranked_cvs_data = result.get("ranked_cvs", [])
        else:
            raise ValueError(f"RÃ©ponse LLM invalide (ni array ni objet avec 'ranked_cvs'): {result}")

        if not ranked_cvs_data:
            raise ValueError(f"ranked_cvs est vide. RÃ©ponse complÃ¨te: {result}")

        # DEBUG: Log ce que le LLM retourne
        print(f"[DEBUG xAI] Type ranked_cvs_data: {type(ranked_cvs_data)}")
        print(f"[DEBUG xAI] Nombre d'items: {len(ranked_cvs_data)}")
        print(f"[DEBUG xAI] Types des items: {[type(item) for item in ranked_cvs_data[:5]]}")

        # FILTRER les items invalides (None, scalaires, non-dict)
        ranked_cvs_valid = [cv for cv in ranked_cvs_data if isinstance(cv, dict)]
        if len(ranked_cvs_valid) != len(ranked_cvs_data):
            invalid_count = len(ranked_cvs_data) - len(ranked_cvs_valid)
            print(f"âš ï¸ [xAI] {invalid_count} items invalides ignorÃ©s dans ranked_cvs")
            print(f"   Items invalides: {[cv for cv in ranked_cvs_data if not isinstance(cv, dict)][:3]}")

        if not ranked_cvs_valid:
            raise ValueError(f"Aucun CV valide dans ranked_cvs (tous null/invalides). Total items: {len(ranked_cvs_data)}")

        # Enrichir (mÃªme logique que OpenAI)
        cv_map_by_name = {cv.get('cv'): cv for cv in cvs_to_rerank}
        cv_summaries_by_name = {s['nom_fichier']: s for s in cv_summaries}

        enriched_result = []
        for reranked_cv in ranked_cvs_valid:  # âœ… Utiliser la liste filtrÃ©e
            cv_name = reranked_cv.get("cv", "inconnu")
            summary = cv_summaries_by_name.get(cv_name, {})
            candidate_name = summary.get("candidate_name") or cv_name

            # NORMALISER les valeurs null retournÃ©es par le LLM
            evidences = reranked_cv.get("evidences") or []
            evidence_map = reranked_cv.get("evidence_map") or {}
            flags_raw = summary.get("flags_raw") or {}

            enriched_result.append({
                "cv": cv_name,
                "candidate_name": candidate_name,
                "coefficient_qualite_experience": reranked_cv.get("coefficient_qualite_experience", 1.0),
                "commentaire_scoring": reranked_cv.get("commentaire_scoring", ""),
                "appreciation_globale": reranked_cv.get("appreciation_globale", ""),
                "evidences": evidences,
                "evidence_map": evidence_map,
                "flags_raw": flags_raw
            })

        print(f"âœ… Re-ranking xAI (Grok): {len(enriched_result)} CVs retournÃ©s")
        return enriched_result

    def _normalize_reranked(self, result):
        """
        Normalise le rÃ©sultat du re-ranking
        """
        items = []
        if isinstance(result, dict):
            items = result.get("ranked_cvs", [])
        elif isinstance(result, list):
            items = result
        else:
            return []

        out = []
        for it in items:
            # FILTRER les items invalides (str, None, non-dict)
            if not isinstance(it, dict):
                continue
            name = it.get("cv") or it.get("cv_id")
            if not name:
                continue

            commentaire_scoring = it.get("commentaire_scoring", "")
            appreciation_globale = it.get("appreciation_globale", "")

            if not commentaire_scoring and not appreciation_globale:
                old_comment = it.get("commentaire") or it.get("justification", "")
                appreciation_globale = old_comment

            out.append({
                "cv": name,
                "commentaire_scoring": commentaire_scoring,
                "appreciation_globale": appreciation_globale,
                "score": it.get("score", 0.0)
            })
        return out

    def _safe_json_parse(self, content: str):
        """Parse JSON robuste avec fallback"""
        content = content.strip()

        # Nettoyer les balises markdown
        if content.startswith("```") and content.endswith("```"):
            content = re.sub(r'^```(?:json)?\s*', '', content)
            content = re.sub(r'\s*```$', '', content)
            content = content.strip()

        # Extraire JSON si texte avant/aprÃ¨s
        match = re.search(r'\{[\s\S]*\}', content)
        if match:
            try:
                return json.loads(match.group(0))
            except json.JSONDecodeError:
                pass

        # Fallback
        try:
            return json.loads(content)
        except:
            print(f"âš ï¸ Erreur parsing JSON: {content[:200]}")
            return []


if __name__ == "__main__":
    print("ğŸ§ª Test du MatchingEngine")
    engine = MatchingEngine()
    print(f"âœ… Engine initialisÃ© avec modÃ¨le: {engine.llm_model}")
    print(f"âœ… Embeddings: {engine.embedding_model}")
