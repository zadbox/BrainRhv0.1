# FICHE TECHNIQUE - Brain RH - Migration Frontend

**Date:** 11 octobre 2025
**Version actuelle:** v2.6.5 (Streamlit)
**Objectif:** Migration vers architecture moderne (FastAPI + React ou Django + HTMX)

---

## 1Ô∏è‚É£ STRUCTURE ET FONCTIONNEMENT ACTUEL

### Architecture g√©n√©rale
**Framework actuel:** Streamlit 1.45.1
**Structure:** Application monolithique avec routing multi-niveaux
**Fichiers Python:** 23 fichiers (10 112 lignes de code total)
**Taille projet:** ~51MB (incluant cache et donn√©es)

### Fichiers principaux et leur r√¥le

#### **Core Business Logic (NE PAS CASSER)**
1. **`matching_engine.py`** (58 442 lignes) - **CRITIQUE**
   - Moteur de matching CV/Offre avec scoring intelligent
   - Embeddings (SentenceTransformer all-MiniLM-L6-v2)
   - Filtrage must-have avec parall√©lisation (500 CVs max/batch)
   - D√©tection nice-have avec malus multiplicateur
   - Re-ranking LLM (top N CVs avec commentaires)
   - Calcul coefficient qualit√© exp√©rience (√ó1.0 √† √ó1.4)
   - Validation jsonschema + r√©paration auto

2. **`parseur_cv.py`** (12 831 lignes)
   - Extraction texte de PDF (PyPDF2) et DOCX (python-docx)
   - Prompt LLM pour structuration JSON
   - Nettoyage et validation des donn√©es

3. **`parallel_cv_parsing.py`** (13 758 lignes)
   - Parsing parall√©lis√© de CVs (asyncio + Semaphore)
   - Max 500 CVs simultan√©s avec rate limiting (QPS)
   - Performance tracking d√©taill√© (logs avec timestamps ms)
   - Timeout 300s par CV, 1 retry

4. **`must_have_parallel.py`** (7 574 lignes)
   - Filtrage parall√©lis√© des must-have
   - Concurrence: min(len(cvs), 500)
   - QPS: 10.0, timeout: 300s, retries: 1

5. **`nice_have_parallel.py`** (7 212 lignes)
   - D√©tection parall√©lis√©e des nice-have manquants
   - M√™me architecture que must_have_parallel
   - Malus: 0.95^(nb_manquants)

#### **UI et Navigation**
6. **`app.py`** (86 443 lignes) - **INTERFACE PRINCIPALE**
   - Point d'entr√©e Streamlit
   - Routing multi-niveaux: Entreprises > Projets > D√©tail matching
   - Gestion session_state (current_enterprise, current_project)
   - 3 onglets principaux: Pr√©parer l'offre / Charger CVs / Matching
   - Affichage r√©sultats avec m√©triques (score final, score base, malus nice-have, qualit√© XP)
   - Export CSV des r√©sultats

7. **`pages_ui.py`** (44 804 lignes)
   - Pages de gestion Entreprises et Projets
   - CSS personnalis√© avec dark mode
   - Formulaires de cr√©ation/modification
   - Cartes UI avec Material Symbols

#### **Gestion de donn√©es**
8. **`project_manager.py`** (11 206 lignes)
   - CRUD projets de recrutement
   - Stockage JSON dans `projects/`
   - Historique des matchings

9. **`enterprise_manager.py`** (8 214 lignes)
   - CRUD entreprises clientes
   - Stockage JSON dans `enterprises/`
   - Compteur de projets

10. **`offer_enrichment.py`** (15 784 lignes)
    - Enrichissement d'offres via LLM
    - Extraction crit√®res must-have et nice-have
    - Appel API France Travail / ROME

11. **`mapper_offre.py`** (10 556 lignes)
    - Mapping offre vers sections standardis√©es
    - Format compatible avec matching engine

12. **`rome_api.py`** (13 493 lignes)
    - Client API France Travail (codes ROME)
    - OAuth2 + refresh token
    - Enrichissement comp√©tences m√©tier

#### **Configuration et validation**
13. **`config_loader.py`** (7 198 lignes)
    - Chargement `config.yaml`
    - Classe ConfigLoader avec getters typ√©s

14. **`validation.py`** (20 742 lignes)
    - Validation jsonschema pour CVs et offres
    - R√©paration auto des donn√©es invalides
    - Checks non-IA (taille, contenu, format)

15. **`parallel_processing.py`** (13 030 lignes)
    - Pipeline de parall√©lisation g√©n√©rique
    - asyncio + ThreadPoolExecutor

### Fonctionnalit√©s principales

#### **1. Gestion Entreprises/Projets**
- Cr√©er/modifier/supprimer des entreprises clientes
- Cr√©er des projets de recrutement par entreprise
- Archiver/restaurer des projets
- Navigation breadcrumb cliquable

#### **2. Pr√©paration d'offre**
- Saisie manuelle de l'offre d'emploi
- Enrichissement automatique via LLM (GPT-5-mini)
- Enrichissement via API France Travail (codes ROME)
- Classification des crit√®res: Must-have / Nice-to-have / N/A
- S√©lection via selectbox unique (remplace anciens checkboxes)

#### **3. Parsing de CVs**
- Upload fichiers PDF/DOCX (batch ou individuel)
- Parsing parall√©lis√© automatique (lots de 500 max)
- Extraction texte + structuration LLM
- Validation et r√©paration JSON
- Stockage dans `cv_json/`

#### **4. Matching CV/Offre (PIPELINE COMPLET)**

**√âtape 1: Vectorisation**
- Offre vectoris√©e une seule fois
- Tous les CVs vectoris√©s en batch (32)
- Calcul cosine similarity par section

**√âtape 2: Filtrage Must-Have (PARALL√àLE)**
- Appels LLM parall√®les (500 max simultan√©s)
- QPS: 10.0, timeout: 300s, retries: 1
- √âlimination des CVs ne satisfaisant pas les crit√®res √©liminatoires
- Rate limiting pour √©viter throttling OpenAI

**√âtape 3: D√©tection Nice-Have (PARALL√àLE)**
- Appels LLM parall√®les (500 max simultan√©s)
- Identification des nice-have manquants
- Application malus: 0.95^(nb_manquants)

**√âtape 4: Scoring Base**
- Calcul score par section (pond√©rations config.yaml)
- Score base = moyenne pond√©r√©e des similarit√©s

**√âtape 5: Re-ranking LLM (Top N)**
- Top N CVs (slider 5-20, d√©faut 10)
- LLM analyse qualit√© exp√©riences professionnelles
- Attribution coefficient qualit√© XP (√ó1.0 √† √ó1.4):
  - 1.4: Exp√©rience EXCEPTIONNELLE
  - 1.3: Exp√©rience TR√àS FORTE
  - 1.2: Exp√©rience FORTE
  - 1.1: Exp√©rience PERTINENTE
  - 1.0: Exp√©rience CORRECTE
- Commentaire d√©taill√© par CV
- Appr√©ciation globale

**√âtape 6: Score Final**
```
Score Final = Score Base √ó Malus Nice-Have √ó Coefficient Qualit√© XP
```
- Score capp√© entre 0.0 et 1.0

#### **5. Affichage et Export**
- Tableau tri√© par score final d√©croissant
- Carte d√©taill√©e par CV avec:
  - 4 m√©triques: Score final, Score base, Malus nice-have, Qualit√© XP
  - Commentaire du re-ranking (si top N)
  - Nice-have manquants avec badges
  - D√©tails du CV (identit√©, exp√©riences, comp√©tences)
- Export CSV avec toutes les colonnes
- L√©gende explicative du scoring

### Flux utilisateur complet
1. **Lancement:** `streamlit run app.py` (port 8501)
2. **S√©lection entreprise** (ou cr√©ation si premi√®re fois)
3. **S√©lection projet** (ou cr√©ation)
4. **Onglet 1: Pr√©parer l'offre**
   - Saisir offre manuellement
   - OU enrichir via LLM/ROME
   - Classifier crit√®res (Must-have/Nice-to-have/N/A)
5. **Onglet 2: Charger CVs**
   - Upload PDFs/DOCX
   - Parsing automatique (parall√®le)
   - Voir liste des CVs pars√©s
6. **Onglet 3: Matching**
   - Configurer Top N (slider)
   - Lancer matching (automatiquement parall√©lis√©)
   - Consulter r√©sultats
   - Exporter CSV
7. **Retour projets/entreprises** via breadcrumb

---

## 2Ô∏è‚É£ DONN√âES ET TRAITEMENT

### Sources de donn√©es
1. **Fichiers locaux** (prioritaire)
   - CVs: `cv_input/` (PDF, DOCX)
   - CVs pars√©s: `cv_json/` (JSON structur√©s)
   - Offres: `offres/` (JSON par projet)
   - Projets: `projects/` (JSON hi√©rarchique)
   - Entreprises: `enterprises/` (JSON plat)

2. **APIs externes**
   - OpenAI GPT-5-mini (parsing, matching, re-ranking)
   - France Travail / ROME (enrichissement offres)

3. **Cache** (facultatif mais conseill√©)
   - Embeddings: `cache/` (hash SHA256)
   - TTL: 24h

### Taille des donn√©es
- **CVs individuels:** 50-500 KB (PDF/DOCX)
- **CVs JSON:** 5-50 KB par CV
- **Offre:** 5-20 KB
- **Batch typique:** 20-100 CVs par matching
- **Batch max support√©:** Pas de limite technique (lots de 500)
- **Volume total produit:** Quelques centaines de CVs/jour estim√©

### Type d'op√©rations
1. **Lecture/√©criture fichiers** (synchrone)
   - Extraction texte PDF/DOCX
   - S√©rialisation/d√©s√©rialisation JSON

2. **Appels LLM** (asynchrone parall√©lis√©)
   - Parsing CVs (response_format: json_object)
   - Filtrage must-have (response_format: json_object)
   - D√©tection nice-have (response_format: json_object)
   - Re-ranking (response_format: json_object)

3. **Calculs CPU** (synchrone)
   - Embeddings (SentenceTransformer sur CPU)
   - Cosine similarity (numpy)
   - Scoring (formules simples)

4. **I/O r√©seau**
   - OpenAI API (gpt-5-mini)
   - France Travail API (OAuth2 + endpoints ROME)

### Temps de traitement
**Exemple r√©el: 32 CVs**
- Extraction texte: ~15s total (I/O bound)
- Parsing LLM parall√®le: ~2 min (network bound)
- Filtrage must-have: ~1-2 min (network bound)
- D√©tection nice-have: ~1-2 min (network bound)
- Embeddings: ~5s (CPU bound)
- Re-ranking top 10: ~30-60s (network bound)
- **Total: ~5-8 minutes pour 32 CVs**

**Goulot d'√©tranglement:**
- Latence OpenAI (90-120s par CV, d'o√π parall√©lisation n√©cessaire)
- QPS rate limiting (10 req/s configur√©)

### R√©sultats exportables
- **CSV:** `scorecard_results.csv` (score, m√©tadonn√©es, commentaires)
- **JSON:** `scorecard_results.json` (structure compl√®te)
- Historique sauvegard√© dans `projects/{project_id}/historique/`

### Historique
- Conservation de tous les matchings par projet
- Horodatage (ISO 8601)
- Pas de limite de r√©tention configur√©e

---

## 3Ô∏è‚É£ PARTIE LLM

### Mod√®les utilis√©s
**Principal:** OpenAI GPT-5-mini (`gpt-5-mini`)
**Fallbacks:** `gpt-4.1-mini`, `gpt-4o-mini`

**Contraintes techniques GPT-5-mini:**
- Temperature: 1.0 uniquement (pas d'override possible)
- Response format: `json_object` obligatoire pour parsing structur√©
- Latence: 90-120s par appel (anormalement lent, confirme need parall√©lisation)

### Usage LLM par fonctionnalit√©

#### **1. Parsing CVs** (`parseur_cv.py`)
- **Prompt:** `PROMPT_CV_EXTRACTION` (~500 tokens)
- **Input:** Texte brut du CV (1000-5000 tokens)
- **Output:** JSON structur√© (identit√©, comp√©tences, exp√©riences, formations, etc.)
- **Temperature:** 1.0 (d√©faut GPT-5-mini)
- **Mode:** Appels parall√®les (max 500 simultan√©s, QPS 10)

#### **2. Filtrage Must-Have** (`must_have_parallel.py`)
- **Prompt:** Contexte offre + crit√®res must-have + CV
- **Input:** ~2000-4000 tokens
- **Output:** JSON `{"manquants": ["crit√®re1", ...], "raison": "..."}`
- **Mode:** Parall√®le (500 max, QPS 10, timeout 300s, 1 retry)

#### **3. D√©tection Nice-Have** (`nice_have_parallel.py`)
- **Prompt:** Contexte offre + crit√®res nice-have + CV
- **Input:** ~2000-4000 tokens
- **Output:** JSON `{"manquants": ["crit√®re1", ...]}`
- **Mode:** Parall√®le (500 max, QPS 10, timeout 300s, 1 retry)

#### **4. Re-ranking** (`matching_engine.py`)
- **Prompt:** Offre compl√®te + liste Top N CVs + instructions d√©taill√©es
- **Input:** ~5000-10000 tokens (d√©pend du Top N)
- **Output:** JSON structur√©:
  ```json
  {
    "ranked_cvs": [
      {
        "cv": "filename.json",
        "coefficient_qualite_experience": 1.2,
        "commentaire_scoring": "...",
        "appreciation_globale": "..."
      }
    ]
  }
  ```
- **Temperature:** 1.0
- **Mode:** Appel unique (pas parall√©lis√©, re√ßoit tous les Top N d'un coup)

#### **5. Enrichissement Offre** (`offer_enrichment.py`)
- **Prompt:** Description offre brute
- **Output:** JSON avec sections enrichies
- **Temperature:** 1.0
- **Mode:** Appel unique

### Streaming vs Batch
**Mode actuel:** Batch uniquement (pas de streaming)
**Justification:** Besoin de JSON complet pour validation

**Besoin futur (migration):**
- Streaming souhaitable pour UX (feedback progressif)
- Mais n√©cessite parser JSON incr√©mental

### Param√®tres dynamiques
- **Top N re-ranking:** Slider 5-20 (d√©faut 10)
- **QPS:** 10.0 (config.yaml, non expos√© UI)
- **Timeout:** 300s (config.yaml, non expos√© UI)
- **Retries:** 1 (config.yaml, non expos√© UI)
- **Concurrency:** min(len(cvs), 500) (automatique)

### Personnalisation
**Par utilisateur:** Non (pas d'authentification actuellement)
**Par projet:** Oui (chaque projet a son offre et crit√®res)
**Par entreprise:** Oui (isolation des donn√©es)

---

## 4Ô∏è‚É£ INTERFACE ACTUELLE

### Structure multi-page Streamlit
**Routing:**
```
/ (root)
‚îú‚îÄ‚îÄ Accueil Entreprises (si aucune entreprise s√©lectionn√©e)
‚îÇ   ‚îú‚îÄ‚îÄ Liste des entreprises (cartes)
‚îÇ   ‚îî‚îÄ‚îÄ Formulaire de cr√©ation
‚îú‚îÄ‚îÄ Accueil Projets (si entreprise s√©lectionn√©e, pas de projet)
‚îÇ   ‚îú‚îÄ‚îÄ Liste des projets (cartes)
‚îÇ   ‚îî‚îÄ‚îÄ Formulaire de cr√©ation
‚îî‚îÄ‚îÄ D√©tail Projet (si entreprise + projet s√©lectionn√©s)
    ‚îú‚îÄ‚îÄ Breadcrumb: Entreprises > Projets > Nom Projet
    ‚îú‚îÄ‚îÄ Onglet 1: Pr√©parer l'offre
    ‚îú‚îÄ‚îÄ Onglet 2: Charger CVs
    ‚îî‚îÄ‚îÄ Onglet 3: Matching
```

### Navigation
**M√©thode:** `st.session_state` + `st.rerun()`
**√âtat partag√©:**
- `current_enterprise` (ID entreprise)
- `current_project` (ID projet)
- `top_rerank` (slider Top N)
- `critere_classification` (dict classification crit√®res)

**Breadcrumb cliquable:**
- Clic "Entreprises" ‚Üí reset `current_enterprise` + rerun
- Clic "Projets" ‚Üí reset `current_project` + rerun
- Nom projet ‚Üí pas d'action (d√©j√† sur la page)

### Composants principaux par page

#### **Accueil Entreprises**
- Cartes entreprises (HTML/CSS custom)
- Boutons: Voir projets, Modifier, Supprimer
- Formulaire cr√©ation (inputs + submit)
- Dark mode adaptatif (CSS variables)

#### **Accueil Projets**
- Cartes projets (actifs + archiv√©s)
- Badges status (actif/archiv√©)
- Boutons: Ouvrir, Modifier, Archiver/Restaurer
- Formulaire cr√©ation

#### **Onglet 1: Pr√©parer l'offre**
- `st.text_area` (offre brute)
- Boutons: Enrichir via LLM, Enrichir via ROME, Merger
- Affichage crit√®res extraits
- **Selectbox unique** par crit√®re: N/A / Must-have / Nice-to-have
- Badges: [Manuel] ou [IA]
- Sauvegarde automatique dans `offres/offre_parsed.json`

#### **Onglet 2: Charger CVs**
- `st.file_uploader` (multiple, accept PDF/DOCX)
- Bouton "Pr√©parer/Charger" (lance parsing parall√®le)
- Progress bar pendant parsing
- Liste CVs pars√©s (expander par CV)
- D√©tails CV (identit√©, comp√©tences, exp√©riences)

#### **Onglet 3: Matching**
- Slider "Top N" (5-20)
- Bouton "Lancer matching"
- Progress bar multi-√©tapes:
  - Vectorisation
  - Filtrage must-have
  - D√©tection nice-have
  - Scoring
  - Re-ranking
- **Tableau r√©sultats:**
  - Tri par score final d√©croissant
  - Colonnes: CV, Score final, Score base, Malus, Qualit√© XP
- **Cartes d√©taill√©es par CV:**
  - 4 m√©triques (st.metric)
  - Nice-have manquants (badges rouges)
  - Commentaire re-ranking (si top N)
  - Expander identit√©
  - Expander exp√©riences
  - Expander comp√©tences
- Bouton "Exporter CSV"
- L√©gende scoring (expander)

### √âtats partag√©s (session_state)
```python
st.session_state = {
    'current_enterprise': str,  # ID entreprise
    'current_project': str,     # ID projet
    'top_rerank': int,          # Top N slider (5-20)
    'critere_classification': dict,  # {idx: "Must-have"/"Nice-to-have"/"N/A"}
    # ... autres √©tats internes Streamlit
}
```

### Interactions principales
**Form submit:**
- Cr√©ation entreprise/projet
- Sauvegarde offre
- Upload CVs

**Callbacks:**
- Clic bouton "Enrichir" ‚Üí appel LLM ‚Üí mise √† jour offre
- Clic bouton "Lancer matching" ‚Üí pipeline complet ‚Üí affichage r√©sultats
- Clic bouton "Exporter" ‚Üí g√©n√©ration CSV ‚Üí download

**Reruns:**
- Changement de page (entreprise/projet)
- Apr√®s cr√©ation/suppression
- Apr√®s upload CVs
- Apr√®s matching

### Aspect visuel
**Doit-il √™tre reproduit √† l'identique?**
**R√©ponse:** NON, modernisation souhait√©e
**Raison:** CSS custom complexe pour contourner limites Streamlit

**Style actuel:**
- Logo personnalis√© (header)
- CSS variables pour dark mode
- Material Symbols icons
- Cartes avec ombres et hover effects
- Couleurs: Bleu (#4A90E2), Cyan (#5BC0DE)
- Typographie: Roboto (Google Fonts)

**Am√©liorations UX souhait√©es:**
- Drag & drop CVs (actuellement upload basique)
- Tableaux triables/filtrables (actuellement tri fixe)
- Pagination (actuellement scroll infini)
- Notifications toast (actuellement st.success/error)
- Loading skeletons (actuellement spinners basiques)

---

## 5Ô∏è‚É£ CONTEXTE TECHNIQUE

### Environnement Python
**Version:** Python 3.9.6
**OS:** macOS Darwin 24.6.0

### D√©pendances principales
```
streamlit==1.45.1
openai==1.63.2
sentence-transformers==5.1.1
jsonschema==4.23.0
pyyaml>=6.0
PyPDF2==3.0.1
python-docx==1.1.0
pandas==2.3.3
python-dotenv==1.0.0
pytest>=7.0
pytest-asyncio>=0.21.0
```

**Packages syst√®me:**
- Aucune d√©pendance syst√®me critique (pas de C extensions custom)

### D√©ploiement actuel
**Mode:** Local uniquement (`streamlit run app.py`)
**Port:** 8501 (config.yaml)
**Processus:** Single-threaded Streamlit server + asyncio pour parall√©lisation

**Pas de d√©ploiement production actuellement**

### Taille du code
- **23 fichiers Python:** 10 112 lignes totales
- **Fichier le plus volumineux:** `app.py` (86 443 lignes)
- **Fichiers critiques:** `matching_engine.py`, `parallel_cv_parsing.py`, `parseur_cv.py`

### Configuration
**Fichiers:**
1. **`.env`** (secrets)
   ```
   OPENAI_API_KEY=***
   ROME_CLIENT_ID=***
   ROME_CLIENT_SECRET=***
   ```

2. **`config.yaml`** (159 lignes, param√®tres)
   - Mod√®les LLM
   - Timeouts et retries
   - Poids scoring
   - Chemins fichiers
   - Parall√©lisation
   - Validation

3. **`.env.example`** (template)

### Environnement cible souhait√©
**Besoin:**
- D√©ploiement cloud (pas sp√©cifi√©, mais inf√©r√©)
- Scalabilit√© horizontale (si volume augmente)
- CI/CD basique (tests automatiques)

**Stack envisag√©e:**
- Docker (conteneurisation)
- Option 1: VM simple (OVH, DigitalOcean)
- Option 2: Cloud managed (GCP Cloud Run, AWS ECS, Azure Container Apps)

**Pas besoin de Kubernetes** (complexit√© excessive pour ce use case)

---

## 6Ô∏è‚É£ CONTRAINTES ET ATTENTES

### Contraintes techniques

#### **R√©seau**
- OpenAI API: Rate limiting 10 req/s (configurable)
- France Travail API: Rate limit inconnu (non document√© dans code)
- Latence OpenAI: 90-120s par appel (bottleneck identifi√©)

#### **Stockage**
- Volumes actuels: ~51MB projet
- Croissance estim√©e: 100-500 MB/mois (CVs + cache)
- Pas de base de donn√©es relationnelle n√©cessaire (JSON suffit)

#### **RAM**
- Embeddings model: ~100MB en m√©moire
- Batch 500 CVs: ~500MB RAM estim√©
- Total besoin: 2GB RAM recommand√©

#### **CPU**
- Embeddings: CPU-bound (SentenceTransformer)
- Scoring: n√©gligeable
- Pas de GPU n√©cessaire

#### **Quotas API**
- OpenAI: D√©pend du compte (non sp√©cifi√©)
- Risque throttling si > 10 req/s
- Besoin monitoring usage

### Contraintes de s√©curit√©

#### **Donn√©es sensibles**
- **CVs:** Oui (identit√©, email, t√©l√©phone, adresse)
- **RGPD:** Applicable (France)
- **Audit:** Logging activ√© (config.yaml), mais pas de chiffrement

**Besoins futurs:**
- Authentification utilisateurs (actuellement aucune)
- Chiffrement donn√©es au repos (CVs, offres)
- Logs d'acc√®s et tra√ßabilit√©
- Retention policy (actuellement illimit√©e)

#### **Secrets**
- Actuellement: `.env` local (non versionn√©)
- Besoin futur: Vault ou secrets manager

### Attentes de la migration

#### **1. Meilleure UI** (Priorit√© HAUTE)
- Design moderne et responsive
- Dark mode natif (pas de hacks CSS)
- Composants riches:
  - Drag & drop fichiers
  - Tableaux triables/filtrables/pagin√©s
  - Progress bars √©l√©gantes
  - Notifications toast
  - Loading skeletons
- Moins de reruns (fluidit√©)

#### **2. Meilleure performance** (Priorit√© HAUTE)
- Conserver parall√©lisation (500 CVs simultan√©s)
- Optimiser latence per√ßue:
  - Streaming LLM (feedback progressif)
  - Chargement lazy des CVs
  - Cache navigateur
- Monitoring temps de traitement

#### **3. Modularit√© du code** (Priorit√© MOYENNE)
- S√©paration backend/frontend propre
- API REST document√©e (OpenAPI/Swagger)
- Tests unitaires et d'int√©gration
- Faciliter ajout de nouvelles fonctionnalit√©s

#### **4. Pr√©paration √† l'√©chelle** (Priorit√© MOYENNE)
- Architecture stateless (pour scaling horizontal)
- Queue syst√®me pour jobs longs (matching de 1000+ CVs)
- Monitoring et alerting
- Logs centralis√©s

#### **5. Authentification** (Priorit√© BASSE pour MVP)
- Multi-utilisateurs
- Isolation des donn√©es par compte
- Gestion des permissions (admin/user)

### Fonctionnalit√©s √† conserver absolument
- ‚úÖ Parsing parall√©lis√© des CVs (500 max)
- ‚úÖ Filtrage must-have parall√©lis√©
- ‚úÖ D√©tection nice-have parall√©lis√©e
- ‚úÖ Re-ranking LLM avec coefficient qualit√© XP
- ‚úÖ Export CSV
- ‚úÖ Gestion entreprises/projets
- ‚úÖ Historique des matchings
- ‚úÖ Classification crit√®res (Must-have/Nice-to-have/N/A)

### Fonctionnalit√©s √† am√©liorer
- üîß Upload CVs (remplacer par drag & drop)
- üîß Affichage r√©sultats (tableaux modernes)
- üîß Navigation (moins de reruns, plus fluide)
- üîß Feedback progressif (streaming LLM)

### Fonctionnalit√©s nouvelles (nice-to-have)
- üìù Comparaison de CVs c√¥te √† c√¥te
- üìù Annotations manuelles sur CVs
- üìù Templates d'offres pr√©-remplis
- üìù Dashboard analytics (stats matchings)
- üìù Notifications email (fin de matching)

---

## 7Ô∏è‚É£ POINTS D'ATTENTION POUR L'ARCHITECTE

### ‚ö†Ô∏è Fonctions critiques (NE PAS MODIFIER LA LOGIQUE)
1. **`matching_engine.match_cvs_with_job()`**
   - C≈ìur du syst√®me
   - Pipeline complet de matching
   - Formule scoring valid√©e par utilisateur

2. **Prompts LLM**
   - Tous les prompts ont √©t√© optimis√©s et valid√©s
   - Ne pas modifier sans tests exhaustifs
   - Localisation: `parseur_cv.py`, `matching_engine.py`, `offer_enrichment.py`

3. **Parall√©lisation**
   - Architecture asyncio + Semaphore valid√©e
   - Performances 16x vs s√©quentiel
   - Ne pas casser la logique de batching

### üîç Zones √† investiguer
1. **Latence OpenAI anormalement haute (90-120s/CV)**
   - V√©rifier si reproductible en production
   - Potentiellement li√© au compte dev
   - Monitoring n√©cessaire

2. **Validation JSON**
   - Taux de r√©paration actuel inconnu
   - √Ä logger et monitorer

3. **Cache embeddings**
   - Efficacit√© r√©elle inconnue
   - Mesurer hit rate

### üìä M√©triques √† collecter (post-migration)
- Temps de traitement par √©tape
- Taux d'erreur LLM
- Taux de r√©paration JSON
- Nombre de CVs trait√©s/jour
- Hit rate cache
- Co√ªt API OpenAI

### üèóÔ∏è Recommandations architecture

**Backend:**
- FastAPI (async natif, compatible avec code actuel)
- Pydantic pour validation (remplace jsonschema)
- SQLAlchemy + PostgreSQL (optionnel, JSON suffit pour MVP)
- Celery + Redis pour queue jobs (si > 100 CVs/matching)

**Frontend:**
- React + TypeScript (contr√¥le total, √©cosyst√®me mature)
- TanStack Query (cache et √©tat serveur)
- TanStack Table (tableaux riches)
- shadcn/ui ou MUI (composants)
- React Dropzone (drag & drop)

**D√©ploiement:**
- Docker + docker-compose (dev)
- Cloud Run ou ECS (production)
- GitHub Actions (CI/CD)
- Sentry (monitoring erreurs)

**Migration par phases:**
1. **Phase 1:** Extraire backend en FastAPI (APIs REST)
2. **Phase 2:** Frontend React (pages simples d'abord)
3. **Phase 3:** Migration pages complexes (matching)
4. **Phase 4:** Features avanc√©es (streaming, queue)

---

## 8Ô∏è‚É£ FICHIERS ANNEXES

### Documentation existante
- `README.md` (7 884 lignes) - Guide utilisateur
- `QUICKSTART.md` (6 337 lignes) - Installation rapide
- `SUIVI_PROJET.md` (12 913 lignes) - Historique des versions
- `INDEX.md` (10 133 lignes) - Index de la doc
- Nombreux fichiers `*.md` de fixes et features

### Tests existants
- `test_2cv_matching.py` (6 369 lignes)
- `test_batch_similarity.py` (4 276 lignes)
- `test_matching_complet.py` (6 266 lignes)
- `test_negation_must_have.py` (5 566 lignes)
- `test_parite_seq_parallel.py` (7 672 lignes)
- `test_parsing_performance.py` (1 891 lignes)
- `test_v2_integration.py` (12 957 lignes)

**Couverture:** Partielle (tests fonctionnels principalement)

### Scripts utilitaires
- `launch_app.sh` (260 lignes) - Lancement simplifi√©
- `migrate_to_enterprises.py` (2 921 lignes) - Migration donn√©es

---

## 9Ô∏è‚É£ R√âSUM√â EX√âCUTIF

### Projet actuel
- **Nom:** Brain RH - Syst√®me de Matching CV/RH
- **Version:** 2.6.5
- **Framework:** Streamlit (Python)
- **Lignes de code:** 10 112 (23 fichiers)
- **Statut:** Fonctionnel, optimis√©, mais UI limit√©e

### Raison de la migration
- Streamlit trop limitant pour UI riche
- Reruns complets √† chaque interaction
- Difficile de customiser l'apparence
- Pas adapt√© pour scaling

### Forces √† conserver
- ‚úÖ Logique m√©tier solide (matching engine)
- ‚úÖ Parall√©lisation performante (16x speedup)
- ‚úÖ Prompts LLM optimis√©s
- ‚úÖ Pipeline valid√© par utilisateur

### Points faibles √† corriger
- ‚ùå UI peu flexible (Streamlit)
- ‚ùå Pas d'authentification
- ‚ùå Pas de queue pour jobs longs
- ‚ùå Donn√©es sensibles non chiffr√©es
- ‚ùå Monitoring absent

### Stack recommand√©e
- **Backend:** FastAPI + Pydantic + asyncio
- **Frontend:** React + TypeScript + TanStack
- **D√©ploiement:** Docker + Cloud Run/ECS
- **Base de donn√©es:** JSON ‚Üí PostgreSQL (optionnel)
- **Queue:** Celery + Redis (si besoin)

### Prochaines √©tapes
1. ChatGPT g√©n√®re plan de migration d√©taill√©
2. Cr√©ation squelette FastAPI + React
3. Migration progressive par fonctionnalit√©
4. Tests de parit√© avec version Streamlit
5. D√©ploiement progressif (canary)

---

**Fin de la fiche technique**
**Document g√©n√©r√© le:** 11 octobre 2025
**Contact:** houssam@brain-rh.com (exemple)
